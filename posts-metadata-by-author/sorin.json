{"https://www.freecodecamp.org/news/author/sorin/":{"/news/how-to-scrape-websites-with-python-2/":{"metadata":[{"tagName":"meta","attributes":{"charset":"utf-8"},"content":""},{"tagName":"meta","attributes":{"http-equiv":"X-UA-Compatible","content":"IE=edge"},"content":""},{"tagName":"title","attributes":{},"content":"Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python"},{"tagName":"meta","attributes":{"name":"HandheldFriendly","content":"True"},"content":""},{"tagName":"meta","attributes":{"name":"viewport","content":"width=device-width, initial-scale=1.0"},"content":""},{"tagName":"link","attributes":{"rel":"preconnect","href":"https://fonts.googleapis.com"},"content":""},{"tagName":"link","attributes":{"rel":"preconnect","href":"https://fonts.gstatic.com","crossorigin":""},"content":""},{"tagName":"link","attributes":{"rel":"preload","as":"style","onload":"this.onload=null;this.rel='stylesheet'","href":"https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,400&family=Roboto+Mono:wght@400;700&display=swap"},"content":""},{"tagName":"link","attributes":{"rel":"preload","as":"style","onload":"this.onload=null;this.rel='stylesheet'","href":"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/themes/prism.min.css"},"content":""},{"tagName":"noscript","attributes":{},"content":"\n  <link rel=\"stylesheet\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/themes/prism.min.css\">\n"},{"tagName":"link","attributes":{"rel":"preload","as":"style","onload":"this.onload=null;this.rel='stylesheet'","href":"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/unescaped-markup/prism-unescaped-markup.min.css"},"content":""},{"tagName":"noscript","attributes":{},"content":"\n  <link rel=\"stylesheet\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/unescaped-markup/prism-unescaped-markup.min.css\">\n"},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/components/prism-core.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"},"content":""},{"tagName":"link","attributes":{"rel":"preload","as":"style","onload":"this.onload=null;this.rel='stylesheet'","href":"/news/assets/css/global-26e2f3cde9.css"},"content":""},{"tagName":"link","attributes":{"rel":"stylesheet","type":"text/css","href":"/news/assets/css/screen-926fddfac2.css"},"content":""},{"tagName":"link","attributes":{"rel":"stylesheet","type":"text/css","href":"/news/assets/css/search-bar-124f5f949c.css"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/algolia/algoliasearch-3-33-0/algoliasearch.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/algolia/autocomplete-0-36-0/autocomplete.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/dayjs.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/localizedFormat.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/relativeTime.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/locale/en.min.js"},"content":""},{"tagName":"script","attributes":{},"content":"let client,index;document.addEventListener(\"DOMContentLoaded\",(()=>{client=algoliasearch(\"QMJYL5WYTI\",\"89770b24481654192d7a5c402c6ad9a0\"),index=client.initIndex(\"news\")})),document.addEventListener(\"DOMContentLoaded\",(()=>{const e=window.screen.width,t=window.screen.height,n=e>=767&&t>=768?8:5,o=document.getElementById(\"search-form\"),s=document.getElementById(\"search-input\"),a=document.getElementById(\"dropdown-container\");let i,d,c;s.addEventListener(\"input\",(e=>{i=e.target.value})),o.addEventListener(\"submit\",(e=>{e.preventDefault(),function(){if(d=document.getElementsByClassName(\"aa-cursor\")[0],d&&i){const e=d.querySelector(\"a\").href;window.location.assign(e)}else!d&&i&&c&&window.location.assign(`https://www.freecodecamp.org/news/search?query=${i}`)}()}));const l=autocomplete(\"#search-input\",{hint:!1,keyboardShortcuts:[\"s\",191],openOnFocus:!0,appendTo:a,debug:!0},[{source:autocomplete.sources.hits(index,{hitsPerPage:n}),debounce:250,templates:{suggestion:e=>(c=!0,`\\n            <a href=\"${e.url}\">\\n              <div class=\"algolia-result\">\\n                <span>${e._highlightResult.title.value}</span>\\n              </div>\\n            </a>\\n          `),empty:()=>(c=!1,'\\n            <div class=\"aa-suggestion footer-suggestion no-hits-footer\">\\n              <div class=\"algolia-result\">\\n                <span>\\n                  No tutorials found\\n                </span>\\n              </div>\\n            </div>\\n          '),footer:e=>{if(!e.isEmpty)return`\\n              <div class=\"aa-suggestion footer-suggestion\">\\n                <a id=\"algolia-footer-selector\" href=\"https://www.freecodecamp.org/news/search?query=${i}\">\\n                  <div class=\"algolia-result algolia-footer\">\\n                    See all results for ${i}\\n                  </div>\\n                </a>\\n              </div>\\n            `}}}]).on(\"autocomplete:selected\",((e,t,n,o)=>{d=t?t.url:`https://www.freecodecamp.org/news/search?query=${i}`,\"click\"!==o.selectionMethod&&\"tabKey\"!==o.selectionMethod&&c&&window.location.assign(d)}));document.addEventListener(\"click\",(e=>{e.target!==s&&l.autocomplete.close()}))})),document.addEventListener(\"DOMContentLoaded\",(()=>{dayjs.extend(dayjs_plugin_localizedFormat),dayjs.extend(dayjs_plugin_relativeTime),dayjs.locale(\"en\")}));const isAuthenticated=document.cookie.split(\";\").some((e=>e.trim().startsWith(\"jwt_access_token=\"))),isDonor=document.cookie.split(\";\").some((e=>e.trim().startsWith(\"isDonor=true\")));"},{"tagName":"script","attributes":{"data-ad-client":"ca-pub-9482786369113753","src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js","crossorigin":"anonymous","async":""},"content":""},{"tagName":"link","attributes":{"rel":"icon","href":"https://cdn.freecodecamp.org/universal/favicons/favicon.ico","type":"image/png"},"content":""},{"tagName":"link","attributes":{"rel":"canonical","href":"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/"},"content":""},{"tagName":"meta","attributes":{"name":"referrer","content":"no-referrer-when-downgrade"},"content":""},{"tagName":"meta","attributes":{"name":"description","content":"Web scraping is the process of extracting specific data from the internet automatically. It has many use cases, like getting data for a machine learning project, creating a price comparison tool, or any other innovative idea that requires an immense amount of data. While you can theoretically do data extraction"},"content":""},{"tagName":"meta","attributes":{"property":"og:site_name","content":"freeCodeCamp.org"},"content":""},{"tagName":"meta","attributes":{"property":"og:type","content":"article"},"content":""},{"tagName":"meta","attributes":{"property":"og:title","content":"Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python"},"content":""},{"tagName":"meta","attributes":{"property":"og:description","content":"Web scraping is the process of extracting specific data from the internet automatically. It has many use cases, like getting data for a machine learning project, creating a price comparison tool, or any other innovative idea that requires an immense amount of data. While you can theoretically do data extraction"},"content":""},{"tagName":"meta","attributes":{"property":"og:url","content":"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/"},"content":""},{"tagName":"meta","attributes":{"property":"og:image","content":"https://www.freecodecamp.org/news/content/images/2021/08/how-to-scrape-data-from-any-website-with-python.jpg"},"content":""},{"tagName":"meta","attributes":{"property":"article:published_time","content":"2021-08-10T17:42:52.000Z"},"content":""},{"tagName":"meta","attributes":{"property":"article:modified_time","content":"2021-08-10T17:42:52.000Z"},"content":""},{"tagName":"meta","attributes":{"property":"article:tag","content":"Python"},"content":""},{"tagName":"meta","attributes":{"property":"article:tag","content":"Web Scraping"},"content":""},{"tagName":"meta","attributes":{"property":"article:publisher","content":"https://www.facebook.com/freecodecamp"},"content":""},{"tagName":"meta","attributes":{"property":"article:author","content":"marica.sorin.9/"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:card","content":"summary_large_image"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:title","content":"Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:description","content":"Web scraping is the process of extracting specific data from the internet automatically. It has many use cases, like getting data for a machine learning project, creating a price comparison tool, or any other innovative idea that requires an immense amount of data. While you can theoretically do data extraction"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:url","content":"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:image","content":"https://www.freecodecamp.org/news/content/images/2021/08/how-to-scrape-data-from-any-website-with-python.jpg"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:label1","content":"Written by"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:data1","content":"Sorin-Gabriel Marica"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:label2","content":"Filed under"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:data2","content":"Python, Web Scraping"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:site","content":"@freecodecamp"},"content":""},{"tagName":"meta","attributes":{"property":"og:image:width","content":"2240"},"content":""},{"tagName":"meta","attributes":{"property":"og:image:height","content":"1260"},"content":""},{"tagName":"script","attributes":{"type":"application/ld+json"},"content":"{\n\t\"@context\": \"https://schema.org\",\n\t\"@type\": \"Article\",\n\t\"publisher\": {\n\t\t\"@type\": \"Organization\",\n\t\t\"name\": \"freeCodeCamp.org\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/\",\n\t\t\"logo\": {\n\t\t\t\"@type\": \"ImageObject\",\n\t\t\t\"url\": \"https://cdn.freecodecamp.org/platform/universal/fcc_primary.svg\",\n\t\t\t\"width\": 2100,\n\t\t\t\"height\": 240\n\t\t}\n\t},\n\t\"image\": {\n\t\t\"@type\": \"ImageObject\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/content/images/2021/08/how-to-scrape-data-from-any-website-with-python.jpg\",\n\t\t\"width\": 2240,\n\t\t\"height\": 1260\n\t},\n\t\"url\": \"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/\",\n\t\"mainEntityOfPage\": {\n\t\t\"@type\": \"WebPage\",\n\t\t\"@id\": \"https://www.freecodecamp.org/news/\"\n\t},\n\t\"datePublished\": \"2021-08-10T17:42:52.000Z\",\n\t\"dateModified\": \"2021-08-10T17:42:52.000Z\",\n\t\"keywords\": \"Python, Web Scraping\",\n\t\"description\": \"Web scraping is the process of extracting specific data from the internet\\nautomatically. It has many use cases, like getting data for a machine learning\\nproject, creating a price comparison tool, or any other innovative idea that\\nrequires an immense amount of data.\\n\\nWhile you can theoretically do data extraction manually, the vast contents of\\nthe internet makes this approach unrealistic in many cases. So knowing how to\\nbuild a web scraper can come in handy. \\n\\nThis article’s purpose is to teach y\",\n\t\"headline\": \"Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python\",\n\t\"author\": {\n\t\t\"@type\": \"Person\",\n\t\t\"name\": \"Sorin-Gabriel Marica\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/author/sorin/\",\n\t\t\"sameAs\": [\n\t\t\t\"https://www.facebook.com/marica.sorin.9/\"\n\t\t],\n\t\t\"image\": {\n\t\t\t\"@type\": \"ImageObject\",\n\t\t\t\"url\": \"https://www.freecodecamp.org/news/content/images/2021/08/118658612_2639508656269377_58101956583589831_n.jpg\",\n\t\t\t\"width\": 600,\n\t\t\t\"height\": 400\n\t\t}\n\t}\n}"},{"tagName":"meta","attributes":{"name":"generator","content":"Eleventy"},"content":""},{"tagName":"link","attributes":{"rel":"alternate","type":"application/rss+xml","title":"freeCodeCamp.org","href":"https://www.freecodecamp.org/news/rss/"},"content":""},{"tagName":"link","attributes":{"rel":"preconnect","href":"https://fonts.gstatic.com"},"content":""},{"tagName":"script","attributes":{},"content":"\nwindow.dataLayer = window.dataLayer || [];\n"},{"tagName":"script","attributes":{},"content":"(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\nnew Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\nj=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n})(window,document,'script','dataLayer','GTM-5D6RKKP');"},{"tagName":"meta","attributes":{"name":"google-site-verification","content":"b4tITLzEeeZGEpvD4mGNf3khKM4fvqejQaz9SYBQP8E"},"content":""},{"tagName":"meta","attributes":{"name":"x-fcc-source","data-test-label":"x-fcc-source","content":"Ghost"},"content":""}],"html":"<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <meta charset=\"utf-8\">\n        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n        \n        \n            <title>Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python</title>\n        \n        <meta name=\"HandheldFriendly\" content=\"True\">\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n\n        <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n        <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin=\"\">\n        \n            <link rel=\"preload\" as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" href=\"https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,400&family=Roboto+Mono:wght@400;700&display=swap\">\n        \n\n        \n        \n    <link rel=\"preload\" as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/themes/prism.min.css\">\n<noscript>\n  <link rel=\"stylesheet\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/themes/prism.min.css\">\n</noscript>\n<link rel=\"preload\" as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/unescaped-markup/prism-unescaped-markup.min.css\">\n<noscript>\n  <link rel=\"stylesheet\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/unescaped-markup/prism-unescaped-markup.min.css\">\n</noscript>\n\n<script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/components/prism-core.min.js\"></script>\n<script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js\"></script>\n\n\n\n        \n        <link rel=\"preload\" as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" href=\"/news/assets/css/global-26e2f3cde9.css\">\n        <link rel=\"stylesheet\" type=\"text/css\" href=\"/news/assets/css/screen-926fddfac2.css\">\n        <link rel=\"stylesheet\" type=\"text/css\" href=\"/news/assets/css/search-bar-124f5f949c.css\">\n\n        \n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/algolia/algoliasearch-3-33-0/algoliasearch.min.js\"></script>\n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/algolia/autocomplete-0-36-0/autocomplete.min.js\"></script>\n\n        \n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/dayjs.min.js\"></script>\n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/localizedFormat.min.js\"></script>\n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/relativeTime.min.js\"></script>\n\n        \n        \n            <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/locale/en.min.js\"></script>\n        \n\n        \n        <script>let client,index;document.addEventListener(\"DOMContentLoaded\",(()=>{client=algoliasearch(\"QMJYL5WYTI\",\"89770b24481654192d7a5c402c6ad9a0\"),index=client.initIndex(\"news\")})),document.addEventListener(\"DOMContentLoaded\",(()=>{const e=window.screen.width,t=window.screen.height,n=e>=767&&t>=768?8:5,o=document.getElementById(\"search-form\"),s=document.getElementById(\"search-input\"),a=document.getElementById(\"dropdown-container\");let i,d,c;s.addEventListener(\"input\",(e=>{i=e.target.value})),o.addEventListener(\"submit\",(e=>{e.preventDefault(),function(){if(d=document.getElementsByClassName(\"aa-cursor\")[0],d&&i){const e=d.querySelector(\"a\").href;window.location.assign(e)}else!d&&i&&c&&window.location.assign(`https://www.freecodecamp.org/news/search?query=${i}`)}()}));const l=autocomplete(\"#search-input\",{hint:!1,keyboardShortcuts:[\"s\",191],openOnFocus:!0,appendTo:a,debug:!0},[{source:autocomplete.sources.hits(index,{hitsPerPage:n}),debounce:250,templates:{suggestion:e=>(c=!0,`\\n            <a href=\"${e.url}\">\\n              <div class=\"algolia-result\">\\n                <span>${e._highlightResult.title.value}</span>\\n              </div>\\n            </a>\\n          `),empty:()=>(c=!1,'\\n            <div class=\"aa-suggestion footer-suggestion no-hits-footer\">\\n              <div class=\"algolia-result\">\\n                <span>\\n                  No tutorials found\\n                </span>\\n              </div>\\n            </div>\\n          '),footer:e=>{if(!e.isEmpty)return`\\n              <div class=\"aa-suggestion footer-suggestion\">\\n                <a id=\"algolia-footer-selector\" href=\"https://www.freecodecamp.org/news/search?query=${i}\">\\n                  <div class=\"algolia-result algolia-footer\">\\n                    See all results for ${i}\\n                  </div>\\n                </a>\\n              </div>\\n            `}}}]).on(\"autocomplete:selected\",((e,t,n,o)=>{d=t?t.url:`https://www.freecodecamp.org/news/search?query=${i}`,\"click\"!==o.selectionMethod&&\"tabKey\"!==o.selectionMethod&&c&&window.location.assign(d)}));document.addEventListener(\"click\",(e=>{e.target!==s&&l.autocomplete.close()}))})),document.addEventListener(\"DOMContentLoaded\",(()=>{dayjs.extend(dayjs_plugin_localizedFormat),dayjs.extend(dayjs_plugin_relativeTime),dayjs.locale(\"en\")}));const isAuthenticated=document.cookie.split(\";\").some((e=>e.trim().startsWith(\"jwt_access_token=\"))),isDonor=document.cookie.split(\";\").some((e=>e.trim().startsWith(\"isDonor=true\")));</script>\n\n        \n        \n    \n        \n            <script data-ad-client=\"ca-pub-9482786369113753\" src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\" crossorigin=\"anonymous\" async=\"\"></script>\n        \n    \n\n\n        \n        \n    \n        \n    \n        \n    \n\n\n        \n        \n        \n\n        \n        \n\n        <link rel=\"icon\" href=\"https://cdn.freecodecamp.org/universal/favicons/favicon.ico\" type=\"image/png\">\n        \n        \n            <link rel=\"canonical\" href=\"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/\">\n        \n        <meta name=\"referrer\" content=\"no-referrer-when-downgrade\">\n\n        \n\n        \n    <meta name=\"description\" content=\"Web scraping is the process of extracting specific data from the internet automatically. It has many use cases, like getting data for a machine learning project, creating a price comparison tool, or any other innovative idea that requires an immense amount of data. While you can theoretically do data extraction\">\n\n    \n    <meta property=\"og:site_name\" content=\"freeCodeCamp.org\">\n    <meta property=\"og:type\" content=\"article\">\n    <meta property=\"og:title\" content=\"Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python\">\n    \n        <meta property=\"og:description\" content=\"Web scraping is the process of extracting specific data from the internet automatically. It has many use cases, like getting data for a machine learning project, creating a price comparison tool, or any other innovative idea that requires an immense amount of data. While you can theoretically do data extraction\">\n    \n    <meta property=\"og:url\" content=\"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/\">\n    <meta property=\"og:image\" content=\"https://www.freecodecamp.org/news/content/images/2021/08/how-to-scrape-data-from-any-website-with-python.jpg\">\n    <meta property=\"article:published_time\" content=\"2021-08-10T17:42:52.000Z\">\n    <meta property=\"article:modified_time\" content=\"2021-08-10T17:42:52.000Z\">\n    \n        <meta property=\"article:tag\" content=\"Python\">\n    \n        <meta property=\"article:tag\" content=\"Web Scraping\">\n    \n    <meta property=\"article:publisher\" content=\"https://www.facebook.com/freecodecamp\">\n    \n        <meta property=\"article:author\" content=\"marica.sorin.9/\">\n    \n\n    \n    <meta name=\"twitter:card\" content=\"summary_large_image\">\n    <meta name=\"twitter:title\" content=\"Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python\">\n    \n        <meta name=\"twitter:description\" content=\"Web scraping is the process of extracting specific data from the internet automatically. It has many use cases, like getting data for a machine learning project, creating a price comparison tool, or any other innovative idea that requires an immense amount of data. While you can theoretically do data extraction\">\n    \n    <meta name=\"twitter:url\" content=\"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/\">\n    <meta name=\"twitter:image\" content=\"https://www.freecodecamp.org/news/content/images/2021/08/how-to-scrape-data-from-any-website-with-python.jpg\">\n    <meta name=\"twitter:label1\" content=\"Written by\">\n    <meta name=\"twitter:data1\" content=\"Sorin-Gabriel Marica\">\n    <meta name=\"twitter:label2\" content=\"Filed under\">\n    <meta name=\"twitter:data2\" content=\"Python, Web Scraping\">\n    <meta name=\"twitter:site\" content=\"@freecodecamp\">\n    \n\n    <meta property=\"og:image:width\" content=\"2240\">\n    <meta property=\"og:image:height\" content=\"1260\">\n\n\n        \n    <script type=\"application/ld+json\">{\n\t\"@context\": \"https://schema.org\",\n\t\"@type\": \"Article\",\n\t\"publisher\": {\n\t\t\"@type\": \"Organization\",\n\t\t\"name\": \"freeCodeCamp.org\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/\",\n\t\t\"logo\": {\n\t\t\t\"@type\": \"ImageObject\",\n\t\t\t\"url\": \"https://cdn.freecodecamp.org/platform/universal/fcc_primary.svg\",\n\t\t\t\"width\": 2100,\n\t\t\t\"height\": 240\n\t\t}\n\t},\n\t\"image\": {\n\t\t\"@type\": \"ImageObject\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/content/images/2021/08/how-to-scrape-data-from-any-website-with-python.jpg\",\n\t\t\"width\": 2240,\n\t\t\"height\": 1260\n\t},\n\t\"url\": \"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/\",\n\t\"mainEntityOfPage\": {\n\t\t\"@type\": \"WebPage\",\n\t\t\"@id\": \"https://www.freecodecamp.org/news/\"\n\t},\n\t\"datePublished\": \"2021-08-10T17:42:52.000Z\",\n\t\"dateModified\": \"2021-08-10T17:42:52.000Z\",\n\t\"keywords\": \"Python, Web Scraping\",\n\t\"description\": \"Web scraping is the process of extracting specific data from the internet\\nautomatically. It has many use cases, like getting data for a machine learning\\nproject, creating a price comparison tool, or any other innovative idea that\\nrequires an immense amount of data.\\n\\nWhile you can theoretically do data extraction manually, the vast contents of\\nthe internet makes this approach unrealistic in many cases. So knowing how to\\nbuild a web scraper can come in handy. \\n\\nThis article’s purpose is to teach y\",\n\t\"headline\": \"Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python\",\n\t\"author\": {\n\t\t\"@type\": \"Person\",\n\t\t\"name\": \"Sorin-Gabriel Marica\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/author/sorin/\",\n\t\t\"sameAs\": [\n\t\t\t\"https://www.facebook.com/marica.sorin.9/\"\n\t\t],\n\t\t\"image\": {\n\t\t\t\"@type\": \"ImageObject\",\n\t\t\t\"url\": \"https://www.freecodecamp.org/news/content/images/2021/08/118658612_2639508656269377_58101956583589831_n.jpg\",\n\t\t\t\"width\": 600,\n\t\t\t\"height\": 400\n\t\t}\n\t}\n}</script>\n\n\n        <meta name=\"generator\" content=\"Eleventy\">\n        <link rel=\"alternate\" type=\"application/rss+xml\" title=\"freeCodeCamp.org\" href=\"https://www.freecodecamp.org/news/rss/\">\n\n        <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\n\n<!-- dataLayer setup -->\n<script>\nwindow.dataLayer = window.dataLayer || [];\n</script>\n<!-- End dataLayer setup -->\n\n<!-- Google Tag Manager -->\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\nnew Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\nj=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n})(window,document,'script','dataLayer','GTM-5D6RKKP');</script>\n<!-- End Google Tag Manager -->\n\n\n<meta name=\"google-site-verification\" content=\"b4tITLzEeeZGEpvD4mGNf3khKM4fvqejQaz9SYBQP8E\">\n\n        \n        \n\n        \n  <meta name=\"x-fcc-source\" data-test-label=\"x-fcc-source\" content=\"Ghost\">\n\n    </head>\n\n    \n        <body class=\"home-template\">\n    \n        <div class=\"site-wrapper\">\n            <nav class=\"site-nav nav-padding\">\n    <div class=\"site-nav-left\">\n        \n<form id=\"search-form\" data-test-label=\"search-bar\">\n    <div role=\"search\" class=\"searchbox__wrapper\">\n        <label class=\"fcc_sr_only\" for=\"search-input\">\n            Search\n        </label>\n        <input type=\"search\" placeholder=\"\n    Search 11,200+ tutorials\n\" id=\"search-input\">\n        <button type=\"submit\" class=\"ais-SearchBox-submit\">\n            <svg class=\"ais-SearchBox-submitIcon\" xmlns=\"https://www.w3.org/2000/svg\" width=\"10\" height=\"10\" viewBox=\"0 0 40 40\">\n    <path d=\"M26.804 29.01c-2.832 2.34-6.465 3.746-10.426 3.746C7.333 32.756 0 25.424 0 16.378 0 7.333 7.333 0 16.378 0c9.046 0 16.378 7.333 16.378 16.378 0 3.96-1.406 7.594-3.746 10.426l10.534 10.534c.607.607.61 1.59-.004 2.202-.61.61-1.597.61-2.202.004L26.804 29.01zm-10.426.627c7.323 0 13.26-5.936 13.26-13.26 0-7.32-5.937-13.257-13.26-13.257C9.056 3.12 3.12 9.056 3.12 16.378c0 7.323 5.936 13.26 13.258 13.26z\"></path>\n</svg>\n\n            <span class=\"fcc_sr_only\">Submit your search query</span>\n        </button>\n        <div id=\"dropdown-container\"></div>\n    </div>\n</form>\n\n    </div>\n    <div class=\"site-nav-middle\">\n        <a class=\"site-nav-logo\" href=\"https://www.freecodecamp.org/news/\" data-test-label=\"site-nav-logo\"><img src=\"https://cdn.freecodecamp.org/platform/universal/fcc_primary.svg\" alt=\"freeCodeCamp.org\"></a>\n    </div>\n    <div class=\"site-nav-right\">\n        <div class=\"nav-group\">\n            <a class=\"nav-forum\" id=\"nav-forum\" rel=\"noopener noreferrer\" href=\"https://forum.freecodecamp.org/\" target=\"_blank\" data-test-label=\"forum-button\">Forum</a>\n            <a class=\"toggle-button-nav\" id=\"nav-donate\" rel=\"noopener noreferrer\" href=\"https://www.freecodecamp.org/donate/\" target=\"_blank\" data-test-label=\"donate-button\">Donate</a>\n        </div>\n    </div>\n</nav>\n\n\n            \n            <a class=\"banner\" id=\"banner\" data-test-label=\"banner\" rel=\"noopener noreferrer\" target=\"_blank\">\n    <p id=\"banner-text\"></p>\n</a>\n\n\n    \n    <script>document.addEventListener(\"DOMContentLoaded\",(()=>{const e=document.getElementById(\"banner\"),t=document.getElementById(\"banner-text\");isAuthenticated?(t.innerHTML=\"Support our charity and our mission. <span>Donate to freeCodeCamp.org</span>.\",e.href=\"https://www.freecodecamp.org/donate\",e.setAttribute(\"text-variation\",\"authenticated\")):isDonor?(t.innerHTML=\"Thank you for supporting freeCodeCamp through <span>your donations</span>.\",e.href=\"https://www.freecodecamp.org/news/how-to-donate-to-free-code-camp/\",e.setAttribute(\"text-variation\",\"donor\")):(t.innerHTML=\"Learn to code — <span>free 3,000-hour curriculum</span>\",e.href=\"https://www.freecodecamp.org/\",e.setAttribute(\"text-variation\",\"default\"))}));</script>\n\n\n            <div id=\"error-message\"></div>\n\n            \n    <main id=\"site-main\" class=\"post-template site-main outer\">\n        <div class=\"inner ad-layout\">\n            <article class=\"post-full post\">\n                <header class=\"post-full-header\">\n                    <section class=\"post-full-meta\">\n                        <time class=\"post-full-meta-date\" data-test-label=\"post-full-meta-date\" datetime=\"Tue Aug 10 2021 17:42:52 GMT+0000 (Coordinated Universal Time)\">\n                            August 10, 2021\n                        </time>\n                        \n                            <span class=\"date-divider\">/</span>\n                            <a dir=\"ltr\" href=\"/news/tag/python/\">\n                                #Python\n                            </a>\n                        \n                    </section>\n                    <h1 class=\"post-full-title\" data-test-label=\"post-full-title\">Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python</h1>\n                </header>\n                <div class=\"post-full-author-header\" data-test-label=\"author-header-no-bio\">\n                    \n                        \n                            \n    \n    \n    \n\n    <section class=\"author-card\" data-test-label=\"author-card\">\n        \n            \n    <img srcset=\"https://www.freecodecamp.org/news/content/images/size/w60/2021/08/118658612_2639508656269377_58101956583589831_n.jpg 60w\" sizes=\"60px\" src=\"https://www.freecodecamp.org/news/content/images/size/w60/2021/08/118658612_2639508656269377_58101956583589831_n.jpg\" class=\"author-profile-image\" alt=\"Sorin-Gabriel Marica\" width=\"600\" height=\"400\" onerror=\"this.style.display='none'\" data-test-label=\"profile-image\">\n  \n        \n\n        <section class=\"author-card-content author-card-content-no-bio\">\n            <span class=\"author-card-name\">\n                <a href=\"/news/author/sorin/\" data-test-label=\"profile-link\">\n                    \n                        Sorin-Gabriel Marica\n                    \n                </a>\n            </span>\n            \n        </section>\n    </section>\n\n                        \n                    \n                </div>\n                <figure class=\"post-full-image\">\n                    \n    <picture>\n      <source media=\"(max-width: 700px)\" sizes=\"1px\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 1w\">\n      <source media=\"(min-width: 701px)\" sizes=\"(max-width: 800px) 400px, (max-width: 1170px) 700px, 1400px\" srcset=\"https://www.freecodecamp.org/news/content/images/size/w300/2021/08/how-to-scrape-data-from-any-website-with-python.jpg 300w, https://www.freecodecamp.org/news/content/images/size/w600/2021/08/how-to-scrape-data-from-any-website-with-python.jpg 600w, https://www.freecodecamp.org/news/content/images/size/w1000/2021/08/how-to-scrape-data-from-any-website-with-python.jpg 1000w, https://www.freecodecamp.org/news/content/images/size/w2000/2021/08/how-to-scrape-data-from-any-website-with-python.jpg 2000w\">\n      <img onerror=\"this.style.display='none'\" src=\"https://www.freecodecamp.org/news/content/images/size/w2000/2021/08/how-to-scrape-data-from-any-website-with-python.jpg\" alt=\"Python Web Scraping Tutorial – How to Scrape Data From Any Website with Python\" ,=\"\" width=\"2240\" height=\"1260\" data-test-label=\"feature-image\">\n    </picture>\n  \n                </figure>\n                <section class=\"post-full-content\">\n                    <div class=\"post-and-sidebar\">\n                        <section class=\"post-content \" data-test-label=\"post-content\">\n                            \n<p>Web scraping is the process of extracting specific data from the internet automatically. It has many use cases, like getting data for a machine learning project, creating a price comparison tool, or any other innovative idea that requires an immense amount of data.</p><p>While you can theoretically do data extraction manually, the vast contents of the internet makes this approach unrealistic in many cases. So knowing how to build a web scraper can come in handy. </p><p>This article’s purpose is to teach you how to create a web scraper in Python. You will learn how to inspect a website to prepare for scraping, extract specific data using BeautifulSoup, wait for JavaScript rendering using Selenium, and save everything in a new JSON or CSV file.</p><p>But first, I should warn you about the legality of web scraping. While the act of scraping is legal, the data you may extract can be illegal to use. Make sure that you're not messing with any:</p><ul><li>Copyrighted content – since it's someone's intellectual property, it's protected by law and you can't just reuse it.</li><li>Personal data – if the information you gather can be used to identify a person, then it's considered personal data and for EU citizens, it's protected under the GDPR. Unless you have a lawful reason to store that data, it's better to just skip it altogether.</li></ul><p>Generally speaking, you should always read a website's terms and conditions before scraping to make sure that you're not going against their policies. If you're ever unsure how to proceed, contact the site owner and ask for consent. </p><h2 id=\"what-will-you-need-for-your-scraper\">What Will You Need for Your Scraper?</h2><p>To start building your own web scraper, you will first need to have <a href=\"https://www.python.org/downloads/\">Python</a> installed on your machine. Ubuntu 20.04 and other versions of Linux come with Python 3 pre-installed. </p><p>To check if you already have Python installed on your device, run the following command:</p><pre><code>python3 -v\n</code></pre><p>If you have Python installed, you should receive an output like this:</p><pre><code>Python 3.8.2</code></pre><p>Also, for our web scraper, we will use the Python packages BeautifulSoup (for selecting specific data) and Selenium (for rendering dynamically loaded content). To install them, just run these commands:</p><pre><code>pip3 install beautifulsoup4</code></pre><p>and</p><pre><code>pip3 install selenium</code></pre><p>The final step it’s to make sure you <a href=\"https://support.google.com/chrome/answer/95346?co=GENIE.Platform%3DDesktop&amp;hl=en\">install Google Chrome</a> and <a href=\"https://chromedriver.chromium.org/downloads\">Chrome Driver</a> on your machine. These will be necessary if we want to use Selenium to scrape dynamically loaded content.</p><h2 id=\"how-to-inspect-the-page\">How to Inspect the Page</h2><p>Now that you have everything installed, it’s time to start our scraping project in earnest. </p><p>You should choose the website you want to scrape based on your needs. Keep in mind that each website structures its content differently, so you’ll need to adjust what you learn here when you start scraping on your own. Each website will require minor changes to the code.</p><p>For this article, I decided to scrape information about the first ten movies from the top 250 movies list from IMDb: <a href=\"https://www.imdb.com/chart/top/\">https://www.imdb.com/chart/top/</a>. </p><p>First, we will get the titles, then we will dive in further by extracting information from each movie’s page. Some of the data will require JavaScript rendering.</p><p>To start understanding the content’s structure, you should right-click on the first title from the list and then choose “Inspect Element”.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://lh4.googleusercontent.com/e6DE3zczzQa-VSBIynK-fR4oyAjVbpx2PztpEDKbi3K0NII9_lFkFhGQmiOjc_-Y_Kg26cM3pecnSKNiPlLZGpntqVKUrcX9E4gDWaTsolWoCFzQ6EEhj3GruBvrlEIzrUffvdjU\" class=\"kg-image\" alt=\"e6DE3zczzQa-VSBIynK-fR4oyAjVbpx2PztpEDKbi3K0NII9_lFkFhGQmiOjc_-Y_Kg26cM3pecnSKNiPlLZGpntqVKUrcX9E4gDWaTsolWoCFzQ6EEhj3GruBvrlEIzrUffvdjU\" width=\"600\" height=\"400\" loading=\"lazy\"></figure><p>By pressing CTRL+F and searching in the HTML code structure, you will see that there is only one <strong>&lt;table&gt;</strong> tag on the page. This is useful as it gives us information about how we can access the data.</p><p>An HTML selector that will give us all of the titles from the page is <strong><code>table tbody tr td.titleColumn a</code></strong>. That’s because all titles are in an anchor inside a table cell with the class “titleColumn”. </p><p>Using this CSS selector and getting the <strong>innerText</strong> of each anchor will give us the titles that we need. You can simulate that in the browser console from the new window you just opened and by using the JavaScript line:</p><pre><code>document.querySelectorAll(\"table tbody tr td.titleColumn a\")[0].innerText</code></pre><p>You will see something like this:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://lh4.googleusercontent.com/T1pgLUXJHX_s3gubDKvBjwkWeK1neZxiysoneD2Q1NU3Sj_pD8defdKorTlcsiiqShlmPDEeCu3Goo5T9CgzPKCml9dq_kCCu7KUyTx7uSrU8VN9QzJZhO6AwBM-kfQ8r0uNxbn9\" class=\"kg-image\" alt=\"T1pgLUXJHX_s3gubDKvBjwkWeK1neZxiysoneD2Q1NU3Sj_pD8defdKorTlcsiiqShlmPDEeCu3Goo5T9CgzPKCml9dq_kCCu7KUyTx7uSrU8VN9QzJZhO6AwBM-kfQ8r0uNxbn9\" width=\"600\" height=\"400\" loading=\"lazy\"></figure><p>Now that we have this selector, we can start writing our Python code and extracting the information we need.</p><h2 id=\"how-to-use-beautifulsoup-to-extract-statically-loaded-content\">How to Use BeautifulSoup to Extract Statically Loaded Content </h2><p>The movie titles from our list are static content. That’s because if you look into the page source (CTRL+U on the page or right-click and then choose View Page Source), you will see that the titles are already there.</p><p>Static content is usually easier to scrape as it doesn’t require JavaScript rendering. To extract the first ten titles on the list, we will use BeautifulSoup to get the content and then print it in the output of our scraper.</p><pre><code class=\"language-Python\">import requests\nfrom bs4 import BeautifulSoup\n \npage = requests.get('https://www.imdb.com/chart/top/') # Getting page HTML through request\nsoup = BeautifulSoup(page.content, 'html.parser') # Parsing content using beautifulsoup\n \nlinks = soup.select(\"table tbody tr td.titleColumn a\") # Selecting all of the anchors with titles\nfirst10 = links[:10] # Keep only the first 10 anchors\nfor anchor in first10:\n    print(anchor.text) # Display the innerText of each anchor\n</code></pre><p>The code above uses the selector we saw in the first step to extract the movie title anchors from the page. It then loops through the first ten and displays the innerText of each.</p><p>The output should look like this:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://lh3.googleusercontent.com/RrmEldjCrbz7V1-o4r6UsKNuWkj_yD2cWwfyuMMbdnRn7lk9cI0yhMi85PK4NrvX7L2KY0pY8047f9CmAeXo1W51HvFENMPxxh36ACqu3kNKuoFNNfhB_WSCMntIB-UB0usEU2n5\" class=\"kg-image\" alt=\"RrmEldjCrbz7V1-o4r6UsKNuWkj_yD2cWwfyuMMbdnRn7lk9cI0yhMi85PK4NrvX7L2KY0pY8047f9CmAeXo1W51HvFENMPxxh36ACqu3kNKuoFNNfhB_WSCMntIB-UB0usEU2n5\" width=\"600\" height=\"400\" loading=\"lazy\"></figure><h2 id=\"how-to-extract-dynamically-loaded-content\">How to Extract Dynamically Loaded Content</h2><p>As technology advanced, websites started to load their content dynamically. This improves the page’s performance, the user's experience, and even removes an extra barrier for scrapers.</p><p>This complicates things, though, as the HTML retrieved from a simple request will not contain the dynamic content. Fortunately, with Selenium, we can simulate a request in the browser and wait for the dynamic content to be displayed.</p><h3 id=\"how-to-use-selenium-for-requests\">How to Use Selenium for Requests</h3><p>You will need to know the location of your chromedriver. The following code is identical to the one presented in the second step, but this time we are using Selenium to make the request. We will still parse the page’s content using BeautifulSoup, as we did before.</p><pre><code class=\"language-Python\">from bs4 import BeautifulSoup\nfrom selenium import webdriver\n \noption = webdriver.ChromeOptions()\n# I use the following options as my machine is a window subsystem linux. \n# I recommend to use the headless option at least, out of the 3\noption.add_argument('--headless')\noption.add_argument('--no-sandbox')\noption.add_argument('--disable-dev-sh-usage')\n# Replace YOUR-PATH-TO-CHROMEDRIVER with your chromedriver location\ndriver = webdriver.Chrome('YOUR-PATH-TO-CHROMEDRIVER', options=option)\n \ndriver.get('https://www.imdb.com/chart/top/') # Getting page HTML through request\nsoup = BeautifulSoup(driver.page_source, 'html.parser') # Parsing content using beautifulsoup. Notice driver.page_source instead of page.content\n \nlinks = soup.select(\"table tbody tr td.titleColumn a\") # Selecting all of the anchors with titles\nfirst10 = links[:10] # Keep only the first 10 anchors\nfor anchor in first10:\n    print(anchor.text) # Display the innerText of each anchor\n</code></pre><p>Don’t forget to replace “YOUR-PATH-TO-CHROMEDRIVER” with the location where you extracted the chromedriver. Also, you should notice that instead of <strong><code>page.content</code></strong>, when we are creating the BeautifulSoup object, we are now using <strong><code>driver.page_source</code></strong>, which provides the HTML content of the page.</p><h3 id=\"how-to-extract-statically-loaded-content-using-selenium\">How to Extract Statically Loaded Content Using Selenium</h3><p>Using the code from above, we can now access each movie page by calling the click method on each of the anchors.</p><pre><code class=\"language-Python\">first_link = driver.find_elements_by_css_selector('table tbody tr td.titleColumn a')[0]\nfirst_link.click()\n</code></pre><p>This will simulate a click on the first movie’s link. However, in this case, I recommend that you continue using <strong><code>driver.get instead</code></strong>. This is because you will no longer be able to use the <strong><code>click()</code></strong> method after you go on a different page since the new page doesn't have links to the other nine movies.</p><p>As a result, after clicking on the first title from the list, you’d need to go back to the first page, then click on the second, and so on. This is a waste of performance and time. Instead, we will just use the extracted links and access them one by one.</p><p>For “The Shawshank Redemption”, the movie page will be <a href=\"https://www.imdb.com/title/tt0111161/\">https://www.imdb.com/title/tt0111161/</a>. We will extract the movie’s year and duration from the page, but this time we will use Selenium’s functions instead of BeautifulSoup as an example. In practice, you can use either one, so pick your favorite.</p><p>To retrieve the movie’s year and duration, you should repeat the first step we went through here on the movie’s page. </p><p>You will notice that you can find all of the information in the first element with the class <strong><code>ipc-inline-list</code></strong> (\".ipc-inline-list\" selector) and that all of the elements of the list contain the attribute <strong><code>role</code></strong> with the value <strong><code>presentation</code></strong> (the <code>[role=’presentation’]</code> selector).</p><pre><code class=\"language-Python\">from bs4 import BeautifulSoup\nfrom selenium import webdriver\n \noption = webdriver.ChromeOptions()\n# I use the following options as my machine is a window subsystem linux. \n# I recommend to use the headless option at least, out of the 3\noption.add_argument('--headless')\noption.add_argument('--no-sandbox')\noption.add_argument('--disable-dev-sh-usage')\n# Replace YOUR-PATH-TO-CHROMEDRIVER with your chromedriver location\ndriver = webdriver.Chrome('YOUR-PATH-TO-CHROMEDRIVER', options=option)\n \npage = driver.get('https://www.imdb.com/chart/top/') # Getting page HTML through request\nsoup = BeautifulSoup(driver.page_source, 'html.parser') # Parsing content using beautifulsoup\n \ntotalScrapedInfo = [] # In this list we will save all the information we scrape\nlinks = soup.select(\"table tbody tr td.titleColumn a\") # Selecting all of the anchors with titles\nfirst10 = links[:10] # Keep only the first 10 anchors\nfor anchor in first10:\n    driver.get('https://www.imdb.com/' + anchor['href']) # Access the movie’s page\n    infolist = driver.find_elements_by_css_selector('.ipc-inline-list')[0] # Find the first element with class ‘ipc-inline-list’\n    informations = infolist.find_elements_by_css_selector(\"[role='presentation']\") # Find all elements with role=’presentation’ from the first element with class ‘ipc-inline-list’\n    scrapedInfo = {\n        \"title\": anchor.text,\n        \"year\": informations[0].text,\n        \"duration\": informations[2].text,\n    } # Save all the scraped information in a dictionary\n    totalScrapedInfo.append(scrapedInfo) # Append the dictionary to the totalScrapedInformation list\n    \nprint(totalScrapedInfo) # Display the list with all the information we scraped\n</code></pre><h3 id=\"how-to-extract-dynamically-loaded-content-using-selenium\">How to Extract Dynamically Loaded Content Using Selenium</h3><p>The next big step in web scraping is extracting content that is loaded dynamically. You can find such content on each of the movie’s pages (such as <a href=\"https://www.imdb.com/title/tt0111161/\">https://www.imdb.com/title/tt0111161/</a>) in the Editorial Lists section. </p><p>If you look using inspect on the page, you'll see that you can find the section as an element with the attribute <strong><code>data-testid</code></strong> set as <strong><code>firstListCardGroup-editorial</code></strong>. But if you look in the page source, you will not find this attribute value anywhere. That’s because the Editorial Lists section is loaded by IMDB dynamically.</p><p>In the following example, we will scrape the editorial list of each movie and add it to our current results of the total scraped information. </p><p>To do that, we will import a few more packages that make it possible to wait for our dynamic content to load.</p><pre><code class=\"language-Python\">from bs4 import BeautifulSoup\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n \noption = webdriver.ChromeOptions()\n# I use the following options as my machine is a window subsystem linux. \n# I recommend to use the headless option at least, out of the 3\noption.add_argument('--headless')\noption.add_argument('--no-sandbox')\noption.add_argument('--disable-dev-sh-usage')\n# Replace YOUR-PATH-TO-CHROMEDRIVER with your chromedriver location\ndriver = webdriver.Chrome('YOUR-PATH-TO-CHROMEDRIVER', options=option)\n \npage = driver.get('https://www.imdb.com/chart/top/') # Getting page HTML through request\nsoup = BeautifulSoup(driver.page_source, 'html.parser') # Parsing content using beautifulsoup\n \ntotalScrapedInfo = [] # In this list we will save all the information we scrape\nlinks = soup.select(\"table tbody tr td.titleColumn a\") # Selecting all of the anchors with titles\nfirst10 = links[:10] # Keep only the first 10 anchors\nfor anchor in first10:\n    driver.get('https://www.imdb.com/' + anchor['href']) # Access the movie’s page \n    infolist = driver.find_elements_by_css_selector('.ipc-inline-list')[0] # Find the first element with class ‘ipc-inline-list’\n    informations = infolist.find_elements_by_css_selector(\"[role='presentation']\") # Find all elements with role=’presentation’ from the first element with class ‘ipc-inline-list’\n    scrapedInfo = {\n        \"title\": anchor.text,\n        \"year\": informations[0].text,\n        \"duration\": informations[2].text,\n    } # Save all the scraped information in a dictionary\n    WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"[data-testid='firstListCardGroup-editorial']\")))  # We are waiting for 5 seconds for our element with the attribute data-testid set as `firstListCardGroup-editorial`\n    listElements = driver.find_elements_by_css_selector(\"[data-testid='firstListCardGroup-editorial'] .listName\") # Extracting the editorial lists elements\n    listNames = [] # Creating an empty list and then appending only the elements texts\n    for el in listElements:\n        listNames.append(el.text)\n    scrapedInfo['editorial-list'] = listNames # Adding the editorial list names to our scrapedInfo dictionary\n    totalScrapedInfo.append(scrapedInfo) # Append the dictionary to the totalScrapedInformation list\n    \nprint(totalScrapedInfo) # Display the list with all the information we scraped\n</code></pre><p>For the previous example, you should get the following output:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://lh4.googleusercontent.com/geHhbKeeP2ATtz-OnIx9MATB3UvXcrobnO4eUNOLrzQll9ebPlq_2PqKaT_oT6e-3h7NmRkRh_9mrDuSvuW3Wbs3sRi1iuM3paCa8HBpTqWrZuSQc8sIu5y4EVZ_5j-60TmPs71Z\" class=\"kg-image\" alt=\"geHhbKeeP2ATtz-OnIx9MATB3UvXcrobnO4eUNOLrzQll9ebPlq_2PqKaT_oT6e-3h7NmRkRh_9mrDuSvuW3Wbs3sRi1iuM3paCa8HBpTqWrZuSQc8sIu5y4EVZ_5j-60TmPs71Z\" width=\"600\" height=\"400\" loading=\"lazy\"></figure><h2 id=\"how-to-save-the-scraped-content\">How to Save the Scraped Content</h2><p>Now that we have all the data we want, we can save it as a .json or a .csv file for easier readability. </p><p>To do that, we will just use the JSON and CVS packages from Python and write our content to new files:</p><pre><code class=\"language-Python\">import csv\nimport json\n \n...\n        \nfile = open('movies.json', mode='w', encoding='utf-8')\nfile.write(json.dumps(totalScrapedInfo))\n \nwriter = csv.writer(open(\"movies.csv\", 'w'))\nfor movie in totalScrapedInfo:\n    writer.writerow(movie.values())\n</code></pre><h2 id=\"scraping-tips-and-tricks\">Scraping Tips and Tricks</h2><p>While our guide so far is already advanced enough to take care of JavaScript rendering scenarios, there are still many things to explore in Selenium. </p><p>In this section, I will share some tips and tricks that may come in handy.</p><h3 id=\"1-time-your-requests\">1. Time your requests</h3><p>If you spam a server with hundreds of requests in a short time, it’s very probable that at some point, a captcha code will appear, or your IP might even get blocked. Unfortunately, there is no workaround in Python to avoid that. </p><p>Therefore, you should put some timeout breaks between each request so that the traffic will look more natural.</p><pre><code class=\"language-Python\">import time\nimport requests\n \npage = requests.get('https://www.imdb.com/chart/top/') # Getting page HTML through request\ntime.sleep(30) # Wait 30 seconds\npage = requests.get('https://www.imdb.com/') # Getting page HTML through request\n</code></pre><h3 id=\"2-error-handling\">2. Error handling</h3><p>Since websites are dynamic and they can change structure at any moment, error handling might come in handy if you use the same web scraper frequently.</p><pre><code class=\"language-Python\">try:\n    WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"your selector\")))\n    break\nexcept TimeoutException:\n    # If the loading took too long, print message and try again\n    print(\"Loading took too much time!\")</code></pre><p>The try and error syntax can be useful when you’re waiting for an element, extracting it, or even when you’re just making the request.</p><h3 id=\"3-take-screenshots\">3. Take Screenshots</h3><p>If you need to obtain a screenshot of the web page you are scraping at any moment, you can use:</p><pre><code class=\"language-Python\">driver.save_screenshot(‘screenshot-file-name.png’)</code></pre><p>This can help debug when you’re working with dynamically loaded content.</p><h3 id=\"4-read-the-documentation\">4. Read the documentation</h3><p>Last but not least, don’t forget to read the <a href=\"https://selenium-python.readthedocs.io/\">documentation from Selenium</a>. This library contains information about how to do most of the actions you can do in a browser. </p><p>Using Selenium, you can fill out forms, press buttons, answer popup messages, and do many other cool things. </p><p>If you’re facing a new problem, their documentation can be your best friend.</p><h2 id=\"final-thoughts\">Final Thoughts</h2><p>This article’s purpose is to give you an advanced introduction to web scraping using Python with Selenium and BeautifulSoup. While there are still many features from both technologies to explore, you now have a solid base on how to start scraping.</p><p>Sometimes web scraping can be very difficult, as websites start to put more and more obstacles in the developer’s way. Some of these obstacles can be Captcha codes, IP blocks, or dynamic content. Overcoming them just with Python and Selenium might be difficult or even impossible. </p><p>So, I’ll give you an alternative as well. Try using a <a href=\"https://webscrapingapi.com\">web scraping API</a> that solves all those challenges for you. It also uses rotating proxies so that you don’t have to worry about adding timeouts between requests. Just remember to always check if the data you want can be lawfully extracted and used.</p>\n\n                        </section>\n                        \n                            <div class=\"sidebar\">\n                                \n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                \n                            </div>\n                        \n                    </div>\n                    <hr>\n                    \n                        <div class=\"post-full-author-header\" data-test-label=\"author-header-with-bio\">\n                            \n                                \n    \n    \n    \n\n    <section class=\"author-card\" data-test-label=\"author-card\">\n        \n            \n    <img srcset=\"https://www.freecodecamp.org/news/content/images/size/w60/2021/08/118658612_2639508656269377_58101956583589831_n.jpg 60w\" sizes=\"60px\" src=\"https://www.freecodecamp.org/news/content/images/size/w60/2021/08/118658612_2639508656269377_58101956583589831_n.jpg\" class=\"author-profile-image\" alt=\"Sorin-Gabriel Marica\" width=\"600\" height=\"400\" onerror=\"this.style.display='none'\" loading=\"lazy\" data-test-label=\"profile-image\">\n  \n        \n\n        <section class=\"author-card-content \">\n            <span class=\"author-card-name\">\n                <a href=\"/news/author/sorin/\" data-test-label=\"profile-link\">\n                    \n                        Sorin-Gabriel Marica\n                    \n                </a>\n            </span>\n            \n                \n                    <p data-test-label=\"author-bio\">I&#39;m a pasionate web developer with big ambitions, currently working at JECO Technology on projects such as WebScrapingAPI.</p>\n                \n            \n        </section>\n    </section>\n\n                            \n                        </div>\n                        <hr>\n                    \n\n                    \n                    \n                        \n    \n\n\n<p data-test-label=\"social-row-cta\" class=\"social-row\">\n    If this article was helpful, <button id=\"tweet-btn\" class=\"cta-button\" data-test-label=\"tweet-button\">share it</button>.\n</p>\n\n\n    \n    <script>document.addEventListener(\"DOMContentLoaded\",(()=>{const t=document.getElementById(\"tweet-btn\"),e=window.location,n=\"Python%20Web%20Scraping%20Tutorial%20%E2%80%93%20How%20to%20Scrape%20Data%20From%20Any%20Website%20with%20Python\".replace(/&#39;/g,\"%27\"),o=\"\",i=\"\",r=Boolean(\"\");let a;if(r&&(o||i)){const t={originalPostAuthor:\"\",currentPostAuthor:\"Sorin-Gabriel Marica\"};a=encodeURIComponent(`Thank you ${o||t.originalPostAuthor} for writing this helpful article, and ${i||t.currentPostAuthor} for translating it.`)}else!r&&i&&(a=encodeURIComponent(`Thank you ${i} for writing this helpful article.`));const c=`window.open(\\n    '${a?`https://twitter.com/intent/tweet?text=${a}%0A%0A${n}%0A%0A${e}`:`https://twitter.com/intent/tweet?text=${n}%0A%0A${e}`}',\\n    'share-twitter',\\n    'width=550, height=235'\\n  ); return false;`;t.setAttribute(\"onclick\",c)}));</script>\n\n\n                        \n\n<div class=\"learn-cta-row\" data-test-label=\"learn-cta-row\">\n    <p>\n        Learn to code for free. freeCodeCamp's open source curriculum has helped more than 40,000 people get jobs as developers. <a href=\"https://www.freecodecamp.org/learn/\" class=\"cta-button\" id=\"learn-to-code-cta\" rel=\"noopener noreferrer\" target=\"_blank\">Get started</a>\n    </p>\n</div>\n\n                    \n                </section>\n                \n                    <div class=\"banner-ad bottom\">\n                        \n                            <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                        \n                    </div>\n                \n            </article>\n        </div>\n    </main>\n\n\n            \n\n\n<footer class=\"site-footer\">\n    <div class=\"footer-top\">\n        <div class=\"footer-desc-col\">\n            <p data-test-label=\"tax-exempt-status\">freeCodeCamp is a donor-supported tax-exempt 501(c)(3) charity organization (United States Federal Tax Identification Number: 82-0779546)</p>\n            <p data-test-label=\"mission-statement\">Our mission: to help people learn to code for free. We accomplish this by creating thousands of videos, articles, and interactive coding lessons - all freely available to the public.</p>\n            <p data-test-label=\"donation-initiatives\">Donations to freeCodeCamp go toward our education initiatives, and help pay for servers, services, and staff.</p>\n            <p class=\"footer-donation\" data-test-label=\"donate-text\">\n                You can <a href=\"https://www.freecodecamp.org/donate/\" class=\"inline\" rel=\"noopener noreferrer\" target=\"_blank\">make a tax-deductible donation here</a>.\n            </p>\n        </div>\n        <div class=\"trending-guides\" data-test-label=\"trending-guides\">\n            <h2 id=\"trending-guides\" class=\"col-header\">Trending Guides</h2>\n            <ul class=\"trending-guides-articles\" aria-labelledby=\"trending-guides\">\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/complete-guide-to-css-transform-functions-and-properties/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn CSS Transform\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/how-to-create-a-static-blog-with-lume/\" rel=\"noopener noreferrer\" target=\"_blank\">Build a Static Blog\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/how-to-build-an-ai-chatbot-with-redis-python-and-gpt/\" rel=\"noopener noreferrer\" target=\"_blank\">Build an AI Chatbot\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/what-is-programming-tutorial-for-beginners/\" rel=\"noopener noreferrer\" target=\"_blank\">What is Programming?\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/python-code-examples-sample-script-coding-tutorial-for-beginners/\" rel=\"noopener noreferrer\" target=\"_blank\">Python Code Examples\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/a-practical-guide-to-start-opensource-contributions/\" rel=\"noopener noreferrer\" target=\"_blank\">Open Source for Devs\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/http-full-course/\" rel=\"noopener noreferrer\" target=\"_blank\">HTTP Networking in JS\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/how-to-write-unit-tests-in-react-redux/\" rel=\"noopener noreferrer\" target=\"_blank\">Write React Unit Tests\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/introduction-to-algorithms-with-javascript-examples/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Algorithms in JS\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/how-to-write-clean-code/\" rel=\"noopener noreferrer\" target=\"_blank\">How to Write Clean Code\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/the-php-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn PHP\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/the-java-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Java\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/the-swift-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Swift\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/learn-golang-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Golang\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/get-started-with-nodejs/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Node.js\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/complete-guide-to-css-grid/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn CSS Grid\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/learn-solidity-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Solidity\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/the-express-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Express.js\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/javascript-es-modules-and-module-bundlers/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn JS Modules\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/apache-kafka-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Apache Kafka\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/rest-api-design-best-practices-build-a-rest-api/\" rel=\"noopener noreferrer\" target=\"_blank\">REST API Best Practices\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/front-end-javascript-development-react-angular-vue-compared/\" rel=\"noopener noreferrer\" target=\"_blank\">Front-End JS Development\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/build-consume-and-document-a-rest-api/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn to Build REST APIs\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/build-strongly-typed-polymorphic-components-with-react-and-typescript/\" rel=\"noopener noreferrer\" target=\"_blank\">Intermediate TS and React\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/command-line-for-beginners/\" rel=\"noopener noreferrer\" target=\"_blank\">Command Line for Beginners\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/an-introduction-to-operating-systems/\" rel=\"noopener noreferrer\" target=\"_blank\">Intro to Operating Systems\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/building-consuming-and-documenting-a-graphql-api/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn to Build GraphQL APIs\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/oss-security-best-practices/\" rel=\"noopener noreferrer\" target=\"_blank\">OSS Security Best Practices\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/design-patterns-for-distributed-systems/\" rel=\"noopener noreferrer\" target=\"_blank\">Distributed Systems Patterns\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/an-introduction-to-software-architecture-patterns/\" rel=\"noopener noreferrer\" target=\"_blank\">Software Architecture Patterns\n                    </a>\n                </li>\n            </ul>\n            <div class=\"spacer\" style=\"padding: 15px 0;\"></div>\n            <div>\n                <h2 id=\"mobile-app\" class=\"col-header\">\n                    Mobile App\n                </h2>\n                <div class=\"min-h-[1px] px-[15px] md:w-2/3 md:ml-[16.6%]\">\n                    <ul aria-labelledby=\"mobile-app\" class=\"mobile-app-container\">\n                        <li>\n                            <a href=\"https://apps.apple.com/us/app/freecodecamp/id6446908151?itsct=apps_box_link&itscg=30200\" rel=\"noopener noreferrer\" target=\"_blank\">\n                                <img src=\"https://cdn.freecodecamp.org/platform/universal/apple-store-badge.svg\" lang=\"en\" alt=\"Download on the App Store\">\n                            </a>\n                        </li>\n                        <li>\n                            <a href=\"https://play.google.com/store/apps/details?id=org.freecodecamp\" rel=\"noopener noreferrer\" target=\"_blank\">\n                                <img src=\"https://cdn.freecodecamp.org/platform/universal/google-play-badge.svg\" lang=\"en\" alt=\"Get it on Google Play\">\n                            </a>\n                        </li>\n                    </ul>\n                </div>\n            </div>\n        </div>\n    </div>\n    <div class=\"footer-bottom\">\n        <h2 class=\"col-header\" data-test-label=\"our-nonprofit\">Our Charity</h2>\n        <div class=\"our-nonprofit\">\n            <a href=\"https://www.freecodecamp.org/news/about/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"about\">\n                About\n            </a>\n            <a href=\"https://www.linkedin.com/school/free-code-camp/people/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"alumni\">\n                Alumni Network\n            </a>\n            <a href=\"https://github.com/freeCodeCamp/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"open-source\">\n                Open Source\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/shop/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"shop\">\n                Shop\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/support/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"support\">\n                Support\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/sponsors/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"sponsors\">\n                Sponsors\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/academic-honesty-policy/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"honesty\">\n                Academic Honesty\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/code-of-conduct/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"coc\">\n                Code of Conduct\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/privacy-policy/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"privacy\">\n                Privacy Policy\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/terms-of-service/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"tos\">\n                Terms of Service\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/copyright-policy/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"copyright\">\n                Copyright Policy\n            </a>\n        </div>\n    </div>\n</footer>\n\n        </div>\n\n        \n        \n        \n\n        <!-- Google Tag Manager (noscript) -->\n<noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-5D6RKKP\" height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\n<!-- End Google Tag Manager (noscript) -->\n\n        \n    <script defer src=\"https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015\" integrity=\"sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==\" data-cf-beacon='{\"rayId\":\"8ac08832f9b16032\",\"version\":\"2024.7.0\",\"serverTiming\":{\"name\":{\"cfL4\":true}},\"token\":\"bdb993c6dde44e178aabd9555e75e4f4\",\"b\":1}' crossorigin=\"anonymous\"></script>\n</body>\n</html>\n"}}}