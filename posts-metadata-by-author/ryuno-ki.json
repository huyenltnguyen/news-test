{"https://www.freecodecamp.org/news/author/ryuno-ki/":{"/news/webscraping-in-python/":{"metadata":[{"tagName":"meta","attributes":{"charset":"utf-8"},"content":""},{"tagName":"meta","attributes":{"http-equiv":"X-UA-Compatible","content":"IE=edge"},"content":""},{"tagName":"title","attributes":{},"content":"How to Scrape Websites with Python 3"},{"tagName":"meta","attributes":{"name":"HandheldFriendly","content":"True"},"content":""},{"tagName":"meta","attributes":{"name":"viewport","content":"width=device-width, initial-scale=1.0"},"content":""},{"tagName":"link","attributes":{"rel":"preconnect","href":"https://fonts.googleapis.com"},"content":""},{"tagName":"link","attributes":{"rel":"preconnect","href":"https://fonts.gstatic.com","crossorigin":""},"content":""},{"tagName":"link","attributes":{"rel":"preload","as":"style","onload":"this.onload=null;this.rel='stylesheet'","href":"https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,400&family=Roboto+Mono:wght@400;700&display=swap"},"content":""},{"tagName":"link","attributes":{"rel":"preload","as":"style","onload":"this.onload=null;this.rel='stylesheet'","href":"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/themes/prism.min.css"},"content":""},{"tagName":"noscript","attributes":{},"content":"\n  <link rel=\"stylesheet\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/themes/prism.min.css\">\n"},{"tagName":"link","attributes":{"rel":"preload","as":"style","onload":"this.onload=null;this.rel='stylesheet'","href":"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/unescaped-markup/prism-unescaped-markup.min.css"},"content":""},{"tagName":"noscript","attributes":{},"content":"\n  <link rel=\"stylesheet\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/unescaped-markup/prism-unescaped-markup.min.css\">\n"},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/components/prism-core.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"},"content":""},{"tagName":"link","attributes":{"rel":"preload","as":"style","onload":"this.onload=null;this.rel='stylesheet'","href":"/news/assets/css/global-26e2f3cde9.css"},"content":""},{"tagName":"link","attributes":{"rel":"stylesheet","type":"text/css","href":"/news/assets/css/screen-926fddfac2.css"},"content":""},{"tagName":"link","attributes":{"rel":"stylesheet","type":"text/css","href":"/news/assets/css/search-bar-124f5f949c.css"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/algolia/algoliasearch-3-33-0/algoliasearch.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/algolia/autocomplete-0-36-0/autocomplete.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/dayjs.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/localizedFormat.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/relativeTime.min.js"},"content":""},{"tagName":"script","attributes":{"defer":"","src":"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/locale/en.min.js"},"content":""},{"tagName":"script","attributes":{},"content":"let client,index;document.addEventListener(\"DOMContentLoaded\",(()=>{client=algoliasearch(\"QMJYL5WYTI\",\"89770b24481654192d7a5c402c6ad9a0\"),index=client.initIndex(\"news\")})),document.addEventListener(\"DOMContentLoaded\",(()=>{const e=window.screen.width,t=window.screen.height,n=e>=767&&t>=768?8:5,o=document.getElementById(\"search-form\"),s=document.getElementById(\"search-input\"),a=document.getElementById(\"dropdown-container\");let i,d,c;s.addEventListener(\"input\",(e=>{i=e.target.value})),o.addEventListener(\"submit\",(e=>{e.preventDefault(),function(){if(d=document.getElementsByClassName(\"aa-cursor\")[0],d&&i){const e=d.querySelector(\"a\").href;window.location.assign(e)}else!d&&i&&c&&window.location.assign(`https://www.freecodecamp.org/news/search?query=${i}`)}()}));const l=autocomplete(\"#search-input\",{hint:!1,keyboardShortcuts:[\"s\",191],openOnFocus:!0,appendTo:a,debug:!0},[{source:autocomplete.sources.hits(index,{hitsPerPage:n}),debounce:250,templates:{suggestion:e=>(c=!0,`\\n            <a href=\"${e.url}\">\\n              <div class=\"algolia-result\">\\n                <span>${e._highlightResult.title.value}</span>\\n              </div>\\n            </a>\\n          `),empty:()=>(c=!1,'\\n            <div class=\"aa-suggestion footer-suggestion no-hits-footer\">\\n              <div class=\"algolia-result\">\\n                <span>\\n                  No tutorials found\\n                </span>\\n              </div>\\n            </div>\\n          '),footer:e=>{if(!e.isEmpty)return`\\n              <div class=\"aa-suggestion footer-suggestion\">\\n                <a id=\"algolia-footer-selector\" href=\"https://www.freecodecamp.org/news/search?query=${i}\">\\n                  <div class=\"algolia-result algolia-footer\">\\n                    See all results for ${i}\\n                  </div>\\n                </a>\\n              </div>\\n            `}}}]).on(\"autocomplete:selected\",((e,t,n,o)=>{d=t?t.url:`https://www.freecodecamp.org/news/search?query=${i}`,\"click\"!==o.selectionMethod&&\"tabKey\"!==o.selectionMethod&&c&&window.location.assign(d)}));document.addEventListener(\"click\",(e=>{e.target!==s&&l.autocomplete.close()}))})),document.addEventListener(\"DOMContentLoaded\",(()=>{dayjs.extend(dayjs_plugin_localizedFormat),dayjs.extend(dayjs_plugin_relativeTime),dayjs.locale(\"en\")}));const isAuthenticated=document.cookie.split(\";\").some((e=>e.trim().startsWith(\"jwt_access_token=\"))),isDonor=document.cookie.split(\";\").some((e=>e.trim().startsWith(\"isDonor=true\")));"},{"tagName":"script","attributes":{"data-ad-client":"ca-pub-9482786369113753","src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js","crossorigin":"anonymous","async":""},"content":""},{"tagName":"link","attributes":{"rel":"icon","href":"https://cdn.freecodecamp.org/universal/favicons/favicon.ico","type":"image/png"},"content":""},{"tagName":"link","attributes":{"rel":"canonical","href":"https://www.freecodecamp.org/news/webscraping-in-python/"},"content":""},{"tagName":"meta","attributes":{"name":"referrer","content":"no-referrer-when-downgrade"},"content":""},{"tagName":"meta","attributes":{"name":"description","content":"Web scraping is the process of extracting data from websites. Before attempting to scrape a website, you should make sure that the provider allows it in their terms of service. You should also check to see whether you could use an API instead. Massive scraping can put a server under"},"content":""},{"tagName":"meta","attributes":{"property":"og:site_name","content":"freeCodeCamp.org"},"content":""},{"tagName":"meta","attributes":{"property":"og:type","content":"article"},"content":""},{"tagName":"meta","attributes":{"property":"og:title","content":"How to Scrape Websites with Python 3"},"content":""},{"tagName":"meta","attributes":{"property":"og:description","content":"Web scraping is the process of extracting data from websites. Before attempting to scrape a website, you should make sure that the provider allows it in their terms of service. You should also check to see whether you could use an API instead. Massive scraping can put a server under"},"content":""},{"tagName":"meta","attributes":{"property":"og:url","content":"https://www.freecodecamp.org/news/webscraping-in-python/"},"content":""},{"tagName":"meta","attributes":{"property":"og:image","content":"https://cdn-media-2.freecodecamp.org/w1280/5f9c9af8740569d1a4ca28f1.jpg"},"content":""},{"tagName":"meta","attributes":{"property":"article:published_time","content":"2020-05-17T22:51:00.000Z"},"content":""},{"tagName":"meta","attributes":{"property":"article:modified_time","content":"2021-04-28T20:25:17.000Z"},"content":""},{"tagName":"meta","attributes":{"property":"article:tag","content":"Web Scraping"},"content":""},{"tagName":"meta","attributes":{"property":"article:tag","content":"Python"},"content":""},{"tagName":"meta","attributes":{"property":"article:publisher","content":"https://www.facebook.com/freecodecamp"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:card","content":"summary_large_image"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:title","content":"How to Scrape Websites with Python 3"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:description","content":"Web scraping is the process of extracting data from websites. Before attempting to scrape a website, you should make sure that the provider allows it in their terms of service. You should also check to see whether you could use an API instead. Massive scraping can put a server under"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:url","content":"https://www.freecodecamp.org/news/webscraping-in-python/"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:image","content":"https://cdn-media-2.freecodecamp.org/w1280/5f9c9af8740569d1a4ca28f1.jpg"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:label1","content":"Written by"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:data1","content":"Andr√© Jaenisch"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:label2","content":"Filed under"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:data2","content":"Web Scraping, Python"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:site","content":"@freecodecamp"},"content":""},{"tagName":"meta","attributes":{"name":"twitter:creator","content":"@AndreJaenisch"},"content":""},{"tagName":"meta","attributes":{"property":"og:image:width","content":"1280"},"content":""},{"tagName":"meta","attributes":{"property":"og:image:height","content":"854"},"content":""},{"tagName":"script","attributes":{"type":"application/ld+json"},"content":"{\n\t\"@context\": \"https://schema.org\",\n\t\"@type\": \"Article\",\n\t\"publisher\": {\n\t\t\"@type\": \"Organization\",\n\t\t\"name\": \"freeCodeCamp.org\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/\",\n\t\t\"logo\": {\n\t\t\t\"@type\": \"ImageObject\",\n\t\t\t\"url\": \"https://cdn.freecodecamp.org/platform/universal/fcc_primary.svg\",\n\t\t\t\"width\": 2100,\n\t\t\t\"height\": 240\n\t\t}\n\t},\n\t\"image\": {\n\t\t\"@type\": \"ImageObject\",\n\t\t\"url\": \"https://cdn-media-2.freecodecamp.org/w1280/5f9c9af8740569d1a4ca28f1.jpg\",\n\t\t\"width\": 1280,\n\t\t\"height\": 854\n\t},\n\t\"url\": \"https://www.freecodecamp.org/news/webscraping-in-python/\",\n\t\"mainEntityOfPage\": {\n\t\t\"@type\": \"WebPage\",\n\t\t\"@id\": \"https://www.freecodecamp.org/news/\"\n\t},\n\t\"datePublished\": \"2020-05-17T22:51:00.000Z\",\n\t\"dateModified\": \"2021-04-28T20:25:17.000Z\",\n\t\"keywords\": \"Web Scraping, Python\",\n\t\"description\": \"Web scraping is the process of extracting data from websites.\\n\\nBefore attempting to scrape a website, you should make sure that the provider\\nallows it in their terms of service. You should also check to see whether you\\ncould use an API instead.\\n\\nMassive scraping can put a server under a lot of stress which can result in a\\ndenial of service. And you don&#x27;t want that.\\n\\nWho should read this?\\nThis article is for advanced readers. It will assume that you are already\\nfamiliar with the Python programmin\",\n\t\"headline\": \"How to Scrape Websites with Python 3\",\n\t\"author\": {\n\t\t\"@type\": \"Person\",\n\t\t\"name\": \"Andr√© Jaenisch\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/author/ryuno-ki/\",\n\t\t\"sameAs\": [\n\t\t\t\"https://jaenis.ch/\",\n\t\t\t\"https://twitter.com/AndreJaenisch\"\n\t\t],\n\t\t\"image\": {\n\t\t\t\"@type\": \"ImageObject\",\n\t\t\t\"url\": \"https://www.freecodecamp.org/news/content/images/2021/05/andre-jaenisch-gravatar.jpeg\",\n\t\t\t\"width\": 250,\n\t\t\t\"height\": 250\n\t\t}\n\t}\n}"},{"tagName":"meta","attributes":{"name":"generator","content":"Eleventy"},"content":""},{"tagName":"link","attributes":{"rel":"alternate","type":"application/rss+xml","title":"freeCodeCamp.org","href":"https://www.freecodecamp.org/news/rss/"},"content":""},{"tagName":"link","attributes":{"rel":"preconnect","href":"https://fonts.gstatic.com"},"content":""},{"tagName":"script","attributes":{},"content":"\nwindow.dataLayer = window.dataLayer || [];\n"},{"tagName":"script","attributes":{},"content":"(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\nnew Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\nj=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n})(window,document,'script','dataLayer','GTM-5D6RKKP');"},{"tagName":"meta","attributes":{"name":"google-site-verification","content":"b4tITLzEeeZGEpvD4mGNf3khKM4fvqejQaz9SYBQP8E"},"content":""},{"tagName":"meta","attributes":{"name":"x-fcc-source","data-test-label":"x-fcc-source","content":"Ghost"},"content":""}],"html":"<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <meta charset=\"utf-8\">\n        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n        \n        \n            <title>How to Scrape Websites with Python 3</title>\n        \n        <meta name=\"HandheldFriendly\" content=\"True\">\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n\n        <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n        <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin=\"\">\n        \n            <link rel=\"preload\" as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" href=\"https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,400&family=Roboto+Mono:wght@400;700&display=swap\">\n        \n\n        \n        \n    <link rel=\"preload\" as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/themes/prism.min.css\">\n<noscript>\n  <link rel=\"stylesheet\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/themes/prism.min.css\">\n</noscript>\n<link rel=\"preload\" as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/unescaped-markup/prism-unescaped-markup.min.css\">\n<noscript>\n  <link rel=\"stylesheet\" href=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/unescaped-markup/prism-unescaped-markup.min.css\">\n</noscript>\n\n<script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/components/prism-core.min.js\"></script>\n<script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js\"></script>\n\n\n\n        \n        <link rel=\"preload\" as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" href=\"/news/assets/css/global-26e2f3cde9.css\">\n        <link rel=\"stylesheet\" type=\"text/css\" href=\"/news/assets/css/screen-926fddfac2.css\">\n        <link rel=\"stylesheet\" type=\"text/css\" href=\"/news/assets/css/search-bar-124f5f949c.css\">\n\n        \n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/algolia/algoliasearch-3-33-0/algoliasearch.min.js\"></script>\n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/algolia/autocomplete-0-36-0/autocomplete.min.js\"></script>\n\n        \n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/dayjs.min.js\"></script>\n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/localizedFormat.min.js\"></script>\n        <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/relativeTime.min.js\"></script>\n\n        \n        \n            <script defer=\"\" src=\"https://cdn.freecodecamp.org/news-assets/dayjs/1.10.4/locale/en.min.js\"></script>\n        \n\n        \n        <script>let client,index;document.addEventListener(\"DOMContentLoaded\",(()=>{client=algoliasearch(\"QMJYL5WYTI\",\"89770b24481654192d7a5c402c6ad9a0\"),index=client.initIndex(\"news\")})),document.addEventListener(\"DOMContentLoaded\",(()=>{const e=window.screen.width,t=window.screen.height,n=e>=767&&t>=768?8:5,o=document.getElementById(\"search-form\"),s=document.getElementById(\"search-input\"),a=document.getElementById(\"dropdown-container\");let i,d,c;s.addEventListener(\"input\",(e=>{i=e.target.value})),o.addEventListener(\"submit\",(e=>{e.preventDefault(),function(){if(d=document.getElementsByClassName(\"aa-cursor\")[0],d&&i){const e=d.querySelector(\"a\").href;window.location.assign(e)}else!d&&i&&c&&window.location.assign(`https://www.freecodecamp.org/news/search?query=${i}`)}()}));const l=autocomplete(\"#search-input\",{hint:!1,keyboardShortcuts:[\"s\",191],openOnFocus:!0,appendTo:a,debug:!0},[{source:autocomplete.sources.hits(index,{hitsPerPage:n}),debounce:250,templates:{suggestion:e=>(c=!0,`\\n            <a href=\"${e.url}\">\\n              <div class=\"algolia-result\">\\n                <span>${e._highlightResult.title.value}</span>\\n              </div>\\n            </a>\\n          `),empty:()=>(c=!1,'\\n            <div class=\"aa-suggestion footer-suggestion no-hits-footer\">\\n              <div class=\"algolia-result\">\\n                <span>\\n                  No tutorials found\\n                </span>\\n              </div>\\n            </div>\\n          '),footer:e=>{if(!e.isEmpty)return`\\n              <div class=\"aa-suggestion footer-suggestion\">\\n                <a id=\"algolia-footer-selector\" href=\"https://www.freecodecamp.org/news/search?query=${i}\">\\n                  <div class=\"algolia-result algolia-footer\">\\n                    See all results for ${i}\\n                  </div>\\n                </a>\\n              </div>\\n            `}}}]).on(\"autocomplete:selected\",((e,t,n,o)=>{d=t?t.url:`https://www.freecodecamp.org/news/search?query=${i}`,\"click\"!==o.selectionMethod&&\"tabKey\"!==o.selectionMethod&&c&&window.location.assign(d)}));document.addEventListener(\"click\",(e=>{e.target!==s&&l.autocomplete.close()}))})),document.addEventListener(\"DOMContentLoaded\",(()=>{dayjs.extend(dayjs_plugin_localizedFormat),dayjs.extend(dayjs_plugin_relativeTime),dayjs.locale(\"en\")}));const isAuthenticated=document.cookie.split(\";\").some((e=>e.trim().startsWith(\"jwt_access_token=\"))),isDonor=document.cookie.split(\";\").some((e=>e.trim().startsWith(\"isDonor=true\")));</script>\n\n        \n        \n    \n        \n            <script data-ad-client=\"ca-pub-9482786369113753\" src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\" crossorigin=\"anonymous\" async=\"\"></script>\n        \n    \n\n\n        \n        \n    \n        \n    \n        \n    \n\n\n        \n        \n        \n\n        \n        \n\n        <link rel=\"icon\" href=\"https://cdn.freecodecamp.org/universal/favicons/favicon.ico\" type=\"image/png\">\n        \n        \n            <link rel=\"canonical\" href=\"https://www.freecodecamp.org/news/webscraping-in-python/\">\n        \n        <meta name=\"referrer\" content=\"no-referrer-when-downgrade\">\n\n        \n\n        \n    <meta name=\"description\" content=\"Web scraping is the process of extracting data from websites. Before attempting to scrape a website, you should make sure that the provider allows it in their terms of service. You should also check to see whether you could use an API instead. Massive scraping can put a server under\">\n\n    \n    <meta property=\"og:site_name\" content=\"freeCodeCamp.org\">\n    <meta property=\"og:type\" content=\"article\">\n    <meta property=\"og:title\" content=\"How to Scrape Websites with Python 3\">\n    \n        <meta property=\"og:description\" content=\"Web scraping is the process of extracting data from websites. Before attempting to scrape a website, you should make sure that the provider allows it in their terms of service. You should also check to see whether you could use an API instead. Massive scraping can put a server under\">\n    \n    <meta property=\"og:url\" content=\"https://www.freecodecamp.org/news/webscraping-in-python/\">\n    <meta property=\"og:image\" content=\"https://cdn-media-2.freecodecamp.org/w1280/5f9c9af8740569d1a4ca28f1.jpg\">\n    <meta property=\"article:published_time\" content=\"2020-05-17T22:51:00.000Z\">\n    <meta property=\"article:modified_time\" content=\"2021-04-28T20:25:17.000Z\">\n    \n        <meta property=\"article:tag\" content=\"Web Scraping\">\n    \n        <meta property=\"article:tag\" content=\"Python\">\n    \n    <meta property=\"article:publisher\" content=\"https://www.facebook.com/freecodecamp\">\n    \n\n    \n    <meta name=\"twitter:card\" content=\"summary_large_image\">\n    <meta name=\"twitter:title\" content=\"How to Scrape Websites with Python 3\">\n    \n        <meta name=\"twitter:description\" content=\"Web scraping is the process of extracting data from websites. Before attempting to scrape a website, you should make sure that the provider allows it in their terms of service. You should also check to see whether you could use an API instead. Massive scraping can put a server under\">\n    \n    <meta name=\"twitter:url\" content=\"https://www.freecodecamp.org/news/webscraping-in-python/\">\n    <meta name=\"twitter:image\" content=\"https://cdn-media-2.freecodecamp.org/w1280/5f9c9af8740569d1a4ca28f1.jpg\">\n    <meta name=\"twitter:label1\" content=\"Written by\">\n    <meta name=\"twitter:data1\" content=\"Andr√© Jaenisch\">\n    <meta name=\"twitter:label2\" content=\"Filed under\">\n    <meta name=\"twitter:data2\" content=\"Web Scraping, Python\">\n    <meta name=\"twitter:site\" content=\"@freecodecamp\">\n    \n        <meta name=\"twitter:creator\" content=\"@AndreJaenisch\">\n    \n\n    <meta property=\"og:image:width\" content=\"1280\">\n    <meta property=\"og:image:height\" content=\"854\">\n\n\n        \n    <script type=\"application/ld+json\">{\n\t\"@context\": \"https://schema.org\",\n\t\"@type\": \"Article\",\n\t\"publisher\": {\n\t\t\"@type\": \"Organization\",\n\t\t\"name\": \"freeCodeCamp.org\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/\",\n\t\t\"logo\": {\n\t\t\t\"@type\": \"ImageObject\",\n\t\t\t\"url\": \"https://cdn.freecodecamp.org/platform/universal/fcc_primary.svg\",\n\t\t\t\"width\": 2100,\n\t\t\t\"height\": 240\n\t\t}\n\t},\n\t\"image\": {\n\t\t\"@type\": \"ImageObject\",\n\t\t\"url\": \"https://cdn-media-2.freecodecamp.org/w1280/5f9c9af8740569d1a4ca28f1.jpg\",\n\t\t\"width\": 1280,\n\t\t\"height\": 854\n\t},\n\t\"url\": \"https://www.freecodecamp.org/news/webscraping-in-python/\",\n\t\"mainEntityOfPage\": {\n\t\t\"@type\": \"WebPage\",\n\t\t\"@id\": \"https://www.freecodecamp.org/news/\"\n\t},\n\t\"datePublished\": \"2020-05-17T22:51:00.000Z\",\n\t\"dateModified\": \"2021-04-28T20:25:17.000Z\",\n\t\"keywords\": \"Web Scraping, Python\",\n\t\"description\": \"Web scraping is the process of extracting data from websites.\\n\\nBefore attempting to scrape a website, you should make sure that the provider\\nallows it in their terms of service. You should also check to see whether you\\ncould use an API instead.\\n\\nMassive scraping can put a server under a lot of stress which can result in a\\ndenial of service. And you don&#x27;t want that.\\n\\nWho should read this?\\nThis article is for advanced readers. It will assume that you are already\\nfamiliar with the Python programmin\",\n\t\"headline\": \"How to Scrape Websites with Python 3\",\n\t\"author\": {\n\t\t\"@type\": \"Person\",\n\t\t\"name\": \"Andr√© Jaenisch\",\n\t\t\"url\": \"https://www.freecodecamp.org/news/author/ryuno-ki/\",\n\t\t\"sameAs\": [\n\t\t\t\"https://jaenis.ch/\",\n\t\t\t\"https://twitter.com/AndreJaenisch\"\n\t\t],\n\t\t\"image\": {\n\t\t\t\"@type\": \"ImageObject\",\n\t\t\t\"url\": \"https://www.freecodecamp.org/news/content/images/2021/05/andre-jaenisch-gravatar.jpeg\",\n\t\t\t\"width\": 250,\n\t\t\t\"height\": 250\n\t\t}\n\t}\n}</script>\n\n\n        <meta name=\"generator\" content=\"Eleventy\">\n        <link rel=\"alternate\" type=\"application/rss+xml\" title=\"freeCodeCamp.org\" href=\"https://www.freecodecamp.org/news/rss/\">\n\n        <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\n\n<!-- dataLayer setup -->\n<script>\nwindow.dataLayer = window.dataLayer || [];\n</script>\n<!-- End dataLayer setup -->\n\n<!-- Google Tag Manager -->\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\nnew Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\nj=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n})(window,document,'script','dataLayer','GTM-5D6RKKP');</script>\n<!-- End Google Tag Manager -->\n\n\n<meta name=\"google-site-verification\" content=\"b4tITLzEeeZGEpvD4mGNf3khKM4fvqejQaz9SYBQP8E\">\n\n        \n        \n\n        \n  <meta name=\"x-fcc-source\" data-test-label=\"x-fcc-source\" content=\"Ghost\">\n\n    </head>\n\n    \n        <body class=\"home-template\">\n    \n        <div class=\"site-wrapper\">\n            <nav class=\"site-nav nav-padding\">\n    <div class=\"site-nav-left\">\n        \n<form id=\"search-form\" data-test-label=\"search-bar\">\n    <div role=\"search\" class=\"searchbox__wrapper\">\n        <label class=\"fcc_sr_only\" for=\"search-input\">\n            Search\n        </label>\n        <input type=\"search\" placeholder=\"\n    Search 11,200+ tutorials\n\" id=\"search-input\">\n        <button type=\"submit\" class=\"ais-SearchBox-submit\">\n            <svg class=\"ais-SearchBox-submitIcon\" xmlns=\"https://www.w3.org/2000/svg\" width=\"10\" height=\"10\" viewBox=\"0 0 40 40\">\n    <path d=\"M26.804 29.01c-2.832 2.34-6.465 3.746-10.426 3.746C7.333 32.756 0 25.424 0 16.378 0 7.333 7.333 0 16.378 0c9.046 0 16.378 7.333 16.378 16.378 0 3.96-1.406 7.594-3.746 10.426l10.534 10.534c.607.607.61 1.59-.004 2.202-.61.61-1.597.61-2.202.004L26.804 29.01zm-10.426.627c7.323 0 13.26-5.936 13.26-13.26 0-7.32-5.937-13.257-13.26-13.257C9.056 3.12 3.12 9.056 3.12 16.378c0 7.323 5.936 13.26 13.258 13.26z\"></path>\n</svg>\n\n            <span class=\"fcc_sr_only\">Submit your search query</span>\n        </button>\n        <div id=\"dropdown-container\"></div>\n    </div>\n</form>\n\n    </div>\n    <div class=\"site-nav-middle\">\n        <a class=\"site-nav-logo\" href=\"https://www.freecodecamp.org/news/\" data-test-label=\"site-nav-logo\"><img src=\"https://cdn.freecodecamp.org/platform/universal/fcc_primary.svg\" alt=\"freeCodeCamp.org\"></a>\n    </div>\n    <div class=\"site-nav-right\">\n        <div class=\"nav-group\">\n            <a class=\"nav-forum\" id=\"nav-forum\" rel=\"noopener noreferrer\" href=\"https://forum.freecodecamp.org/\" target=\"_blank\" data-test-label=\"forum-button\">Forum</a>\n            <a class=\"toggle-button-nav\" id=\"nav-donate\" rel=\"noopener noreferrer\" href=\"https://www.freecodecamp.org/donate/\" target=\"_blank\" data-test-label=\"donate-button\">Donate</a>\n        </div>\n    </div>\n</nav>\n\n\n            \n            <a class=\"banner\" id=\"banner\" data-test-label=\"banner\" rel=\"noopener noreferrer\" target=\"_blank\">\n    <p id=\"banner-text\"></p>\n</a>\n\n\n    \n    <script>document.addEventListener(\"DOMContentLoaded\",(()=>{const e=document.getElementById(\"banner\"),t=document.getElementById(\"banner-text\");isAuthenticated?(t.innerHTML=\"Support our charity and our mission. <span>Donate to freeCodeCamp.org</span>.\",e.href=\"https://www.freecodecamp.org/donate\",e.setAttribute(\"text-variation\",\"authenticated\")):isDonor?(t.innerHTML=\"Thank you for supporting freeCodeCamp through <span>your donations</span>.\",e.href=\"https://www.freecodecamp.org/news/how-to-donate-to-free-code-camp/\",e.setAttribute(\"text-variation\",\"donor\")):(t.innerHTML=\"Learn to code ‚Äî <span>free 3,000-hour curriculum</span>\",e.href=\"https://www.freecodecamp.org/\",e.setAttribute(\"text-variation\",\"default\"))}));</script>\n\n\n            <div id=\"error-message\"></div>\n\n            \n    <main id=\"site-main\" class=\"post-template site-main outer\">\n        <div class=\"inner ad-layout\">\n            <article class=\"post-full post\">\n                <header class=\"post-full-header\">\n                    <section class=\"post-full-meta\">\n                        <time class=\"post-full-meta-date\" data-test-label=\"post-full-meta-date\" datetime=\"Sun May 17 2020 22:51:00 GMT+0000 (Coordinated Universal Time)\">\n                            May 17, 2020\n                        </time>\n                        \n                            <span class=\"date-divider\">/</span>\n                            <a dir=\"ltr\" href=\"/news/tag/web-scraping/\">\n                                #Web Scraping\n                            </a>\n                        \n                    </section>\n                    <h1 class=\"post-full-title\" data-test-label=\"post-full-title\">How to Scrape Websites with Python 3</h1>\n                </header>\n                <div class=\"post-full-author-header\" data-test-label=\"author-header-no-bio\">\n                    \n                        \n                            \n    \n    \n    \n\n    <section class=\"author-card\" data-test-label=\"author-card\">\n        \n            \n    <img srcset=\"https://www.freecodecamp.org/news/content/images/size/w60/2021/05/andre-jaenisch-gravatar.jpeg 60w\" sizes=\"60px\" src=\"https://www.freecodecamp.org/news/content/images/size/w60/2021/05/andre-jaenisch-gravatar.jpeg\" class=\"author-profile-image\" alt=\"Andr√© Jaenisch\" width=\"250\" height=\"250\" onerror=\"this.style.display='none'\" data-test-label=\"profile-image\">\n  \n        \n\n        <section class=\"author-card-content author-card-content-no-bio\">\n            <span class=\"author-card-name\">\n                <a href=\"/news/author/ryuno-ki/\" data-test-label=\"profile-link\">\n                    \n                        Andr√© Jaenisch\n                    \n                </a>\n            </span>\n            \n        </section>\n    </section>\n\n                        \n                    \n                </div>\n                <figure class=\"post-full-image\">\n                    \n    <picture>\n      <source media=\"(max-width: 700px)\" sizes=\"1px\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 1w\">\n      <source media=\"(min-width: 701px)\" sizes=\"(max-width: 800px) 400px, (max-width: 1170px) 700px, 1400px\" srcset=\"https://cdn-media-2.freecodecamp.org/w1280/5f9c9af8740569d1a4ca28f1.jpg\">\n      <img onerror=\"this.style.display='none'\" src=\"https://cdn-media-2.freecodecamp.org/w1280/5f9c9af8740569d1a4ca28f1.jpg\" alt=\"How to Scrape Websites with Python 3\" ,=\"\" width=\"1280\" height=\"854\" data-test-label=\"feature-image\">\n    </picture>\n  \n                </figure>\n                <section class=\"post-full-content\">\n                    <div class=\"post-and-sidebar\">\n                        <section class=\"post-content \" data-test-label=\"post-content\">\n                            \n<p>Web scraping is the process of extracting data from websites.</p><p>Before attempting to scrape a website, you should make sure that the provider allows it in their terms of service. You should also check to see whether you could use an API instead.</p><p>Massive scraping can put a server under a lot of stress which can result in a denial of service. And you don't want that.</p><h2 id=\"who-should-read-this\">Who should read this?</h2><p>This article is for advanced readers. It will assume that you are already familiar with the Python programming language.</p><p>At the very minimum you should understand list comprehension, context manager, and functions. You should also know how to set up a virtual environment.</p><p>We'll run the code on your local machine to explore some websites. With some tweaks you could make it run on a server as well.</p><h2 id=\"what-you-will-learn-in-this-article\">What you will learn in this article</h2><p>At the end of this article, you will know how to download a webpage, parse it for interesting information, and format it in a usable format for further processing. This is also known as <a href=\"https://en.wikipedia.org/wiki/Extract,_transform,_load\">ETL</a>.</p><p>This article will also explain what to do if that website is using JavaScript to render content (like React.js or Angular).</p><h2 id=\"prerequisites\">Prerequisites</h2><p>Before I can start, I want to make sure we're ready to go. Please set up a virtual environment and install the following packages into it:</p><ul><li>beautifulsoup4 (version 4.9.0 at time of writing)</li><li>requests (version 2.23.0 at time of writing)</li><li>wordcloud (version 1.17.0 at time of writing, optional)</li><li>selenium (version 3.141.0 at time of writing, optional)</li></ul><p>You can find the code for this project in this <a href=\"https://github.com/Ryuno-Ki/fcc-web-scraping-example\">git repository on GitHub</a>.</p><p>For this example, we are going to scrape the <a href=\"https://www.gesetze-im-internet.de/gg/index.html\">Basic Law for the Federal Republic of Germany</a>. (Don't worry, I checked their Terms of Service. They offer an XML version for machine processing, but this page serves as an example of processing HTML. So it should be fine.)</p><h2 id=\"step-1-download-the-source\">Step 1: Download the source</h2><p>First things first: I create a file <code>urls.txt</code> holding all the URLs I want to download:</p><figure class=\"kg-card kg-code-card\"><pre><code>https://www.gesetze-im-internet.de/gg/art_1.html\nhttps://www.gesetze-im-internet.de/gg/art_2.html\nhttps://www.gesetze-im-internet.de/gg/art_3.html\nhttps://www.gesetze-im-internet.de/gg/art_4.html\nhttps://www.gesetze-im-internet.de/gg/art_5.html\nhttps://www.gesetze-im-internet.de/gg/art_6.html\nhttps://www.gesetze-im-internet.de/gg/art_7.html\nhttps://www.gesetze-im-internet.de/gg/art_8.html\nhttps://www.gesetze-im-internet.de/gg/art_9.html\nhttps://www.gesetze-im-internet.de/gg/art_10.html\nhttps://www.gesetze-im-internet.de/gg/art_11.html\nhttps://www.gesetze-im-internet.de/gg/art_12.html\nhttps://www.gesetze-im-internet.de/gg/art_12a.html\nhttps://www.gesetze-im-internet.de/gg/art_13.html\nhttps://www.gesetze-im-internet.de/gg/art_14.html\nhttps://www.gesetze-im-internet.de/gg/art_15.html\nhttps://www.gesetze-im-internet.de/gg/art_16.html\nhttps://www.gesetze-im-internet.de/gg/art_16a.html\nhttps://www.gesetze-im-internet.de/gg/art_17.html\nhttps://www.gesetze-im-internet.de/gg/art_17a.html\nhttps://www.gesetze-im-internet.de/gg/art_18.html\nhttps://www.gesetze-im-internet.de/gg/art_19.html</code></pre><figcaption>urls.txt</figcaption></figure><p>Next, I write a bit of Python code in a file called <code>scraper.py</code> to download the HTML of this files. </p><p>In a real scenario, this would be too expensive and you'd use a database instead. To keep things simple, I'll download files into the same directory next to the store and use their name as the filename.</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-py\">from os import path\nfrom pathlib import PurePath\n\nimport requests\n\nwith open('urls.txt', 'r') as fh:\n    urls = fh.readlines()\nurls = [url.strip() for url in urls]  # strip `\\n`\n\nfor url in urls:\n    file_name = PurePath(url).name\n    file_path = path.join('.', file_name)\n    text = ''\n\n    try:\n        response = requests.get(url)\n        if response.ok:\n            text = response.text\n    except requests.exceptions.ConnectionError as exc:\n        print(exc)\n    \n    with open(file_path, 'w') as fh:\n        fh.write(text)\n\n    print('Written to', file_path)</code></pre><figcaption>scraper.py</figcaption></figure><p>By downloading the files, I can process them locally as much as I want without being dependent on a server. Try to be a good web citizen, okay?</p><h2 id=\"step-2-parse-the-source\">Step 2: Parse the source</h2><p>Now that I've downloaded the files, it's time to extract their interesting features. Therefore I go to one of the pages I downloaded, open it in a web browser, and hit Ctrl-U to view its source. Inspecting it will show me the HTML structure.</p><p>In my case, I figured I want the text of the law without any markup. The element wrapping it has an id of <code>container</code>. Using BeautifulSoup I can see that a combination of <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find\"><code>find</code></a> and <code><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/#get-text\">get_text</a></code> will do what I want.</p><p>Since I have a second step now, I'm going to refactor the code a bit by putting it into functions and add a minimal CLI.</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-py\">from os import path\nfrom pathlib import PurePath\nimport sys\n\nfrom bs4 import BeautifulSoup\nimport requests\n\n\ndef download_urls(urls, dir):\n    paths = []\n\n    for url in urls:\n        file_name = PurePath(url).name\n        file_path = path.join(dir, file_name)\n        text = ''\n\n        try:\n            response = requests.get(url)\n            if response.ok:\n                text = response.text\n            else:\n                print('Bad response for', url, response.status_code)\n        except requests.exceptions.ConnectionError as exc:\n            print(exc)\n    \n        with open(file_path, 'w') as fh:\n            fh.write(text)\n\n        paths.append(file_path)\n\n    return paths\n\ndef parse_html(path):\n    with open(path, 'r') as fh:\n        content = fh.read()\n\n    return BeautifulSoup(content, 'html.parser')\n\ndef download(urls):\n    return download_urls(urls, '.')\n\ndef extract(path):\n    return parse_html(path)\n\ndef transform(soup):\n    container = soup.find(id='container')\n    if container is not None:\n        return container.get_text()\n\ndef load(key, value):\n    d = {}\n    d[key] = value\n    return d\n\ndef run_single(path):\n    soup = extract(path)\n    content = transform(soup)\n    unserialised = load(path, content.strip() if content is not None else '')\n    return unserialised\n\ndef run_everything():\n    l = []\n\n    with open('urls.txt', 'r') as fh:\n        urls = fh.readlines()\n    urls = [url.strip() for url in urls]\n\n    paths = download(urls)\n    for path in paths:\n        print('Written to', path)\n        l.append(run_single(path))\n\n    print(l)\n\nif __name__ == \"__main__\":\n    args = sys.argv\n\n    if len(args) is 1:\n      run_everything()\n    else:\n        if args[1] == 'download':\n            download([args[2]])\n            print('Done')\n        if args[1] == 'parse':\n            path = args[2]\n            result = run_single(path)\n            print(result)\n</code></pre><figcaption>scraper.py</figcaption></figure><p>Now I can run the code in three ways:</p><ol><li>Without any arguments to run everything (that is, download all URLs and extract them, then save to disk) via: <code>python scraper.py</code></li><li>With an argument of <code>download</code> and a url to download <code>python scraper.py download https://www.gesetze-im-internet.de/gg/art_1.html</code>. This will not process the file.</li><li>With an argument of <code>parse</code> and a filepath to parse: <code>python scraper.py art_1.html</code>. This will skip the download step.</li></ol><p>With that, there's one last thing missing.</p><h2 id=\"step-3-format-the-source-for-further-processing\">Step 3: Format the source for further processing</h2><p>Let's say I want to generate a word cloud for each article. This can be a quick way to get an idea about what a text is about. For this, install the package <code>wordcloud</code> and update the file like this:</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-py\">from os import path\nfrom pathlib import Path, PurePath\nimport sys\n\nfrom bs4 import BeautifulSoup\nimport requests\nfrom wordcloud import WordCloud\n\nSTOPWORDS_ADDENDUM = [\n    'Das',\n    'Der',\n    'Die',\n    'Diese',\n    'Eine',\n    'In',\n    'InhaltsverzeichnisGrundgesetz',\n    'im',\n    'Jede',\n    'Jeder',\n    'Kein',\n    'Sie',\n    'Soweit',\n    '√úber'\n]\nSTOPWORDS_FILE_PATH = 'stopwords.txt'\nSTOPWORDS_URL = 'https://raw.githubusercontent.com/stopwords-iso/stopwords-de/master/stopwords-de.txt'\n\n\ndef download_urls(urls, dir):\n    paths = []\n\n    for url in urls:\n        file_name = PurePath(url).name\n        file_path = path.join(dir, file_name)\n        text = ''\n\n        try:\n            response = requests.get(url)\n            if response.ok:\n                text = response.text\n            else:\n                print('Bad response for', url, response.status_code)\n        except requests.exceptions.ConnectionError as exc:\n            print(exc)\n    \n        with open(file_path, 'w') as fh:\n            fh.write(text)\n\n        paths.append(file_path)\n\n    return paths\n\ndef parse_html(path):\n    with open(path, 'r') as fh:\n        content = fh.read()\n\n    return BeautifulSoup(content, 'html.parser')\n\ndef download_stopwords():\n    stopwords = ''\n\n    try:\n        response = requests.get(STOPWORDS_URL)\n        if response.ok:\n            stopwords = response.text\n        else:\n            print('Bad response for', url, response.status_code)\n    except requests.exceptions.ConnectionError as exc:\n        print(exc)\n\n    with open(STOPWORDS_FILE_PATH, 'w') as fh:\n        fh.write(stopwords)\n\n    return stopwords\n\ndef download(urls):\n    return download_urls(urls, '.')\n\ndef extract(path):\n    return parse_html(path)\n\ndef transform(soup):\n    container = soup.find(id='container')\n    if container is not None:\n        return container.get_text()\n\ndef load(filename, text):\n    if Path(STOPWORDS_FILE_PATH).exists():\n        with open(STOPWORDS_FILE_PATH, 'r') as fh:\n            stopwords = fh.readlines()\n    else:\n        stopwords = download_stopwords()\n\n    # Strip whitespace around\n    stopwords = [stopword.strip() for stopword in stopwords]\n    # Extend stopwords with own ones, which were determined after first run\n    stopwords = stopwords + STOPWORDS_ADDENDUM\n\n    try:\n        cloud = WordCloud(stopwords=stopwords).generate(text)\n        cloud.to_file(filename.replace('.html', '.png'))\n    except ValueError:\n        print('Could not generate word cloud for', key)\n\ndef run_single(path):\n    soup = extract(path)\n    content = transform(soup)\n    load(path, content.strip() if content is not None else '')\n\ndef run_everything():\n    with open('urls.txt', 'r') as fh:\n        urls = fh.readlines()\n    urls = [url.strip() for url in urls]\n\n    paths = download(urls)\n    for path in paths:\n        print('Written to', path)\n        run_single(path)\n    print('Done')\n\nif __name__ == \"__main__\":\n    args = sys.argv\n\n    if len(args) is 1:\n      run_everything()\n    else:\n        if args[1] == 'download':\n            download([args[2]])\n            print('Done')\n        if args[1] == 'parse':\n            path = args[2]\n            run_single(path)\n            print('Done')</code></pre><figcaption>scraper.py</figcaption></figure><p>What changed? For one, I downloaded a <a href=\"https://github.com/stopwords-iso/stopwords-de/\">list of German stopwords</a> from GitHub. This way, I can eliminate the most common words from the downloaded law text.</p><p>Then I instantiate a WordCloud instance with the list of stopwords I downloaded and the text of the law. It will be turned into an image with the same basename.</p><p>After the first run, I discover that the list of stopwords is incomplete. So I add additional words I want to exclude from the resulting image.</p><p>With that, the main part of web scraping is complete.</p><h2 id=\"bonus-what-about-spas\">Bonus: What about SPAs?</h2><p>SPAs - or Single Page Applications - are web applications where the whole experience is controlled by JavaScript, which is executed in the browser. As such, downloading the HTML file does not bring us far. What should we do instead?</p><p>We'll use the browser. With Selenium. Make sure to <a href=\"https://selenium-python.readthedocs.io/installation.html#drivers\">install a driver</a> also. Download the .tar.gz archive and unpack it in the <code>bin</code> folder of your virtual environment so it will be found by Selenium. That is the directory where you can find the <code>activate</code> script (on GNU/Linux systems).</p><p>As an example, I am using the <a href=\"https://angular.io/\">Angular website</a> here. Angular is a popular SPA-Framework written in JavaScript and guaranteed to be controlled by it for the time being.</p><p>Since the code will be slower, I create a new file called <code>crawler.py</code> for it. The content looks like this:</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-py\">from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom wordcloud import WordCloud\n\ndef extract(url):\n    elem = None\n    driver = webdriver.Firefox()\n    driver.get(url)\n\n    try:\n        found = WebDriverWait(driver, 10).until(\n            EC.visibility_of(\n                driver.find_element(By.TAG_NAME, \"article\")\n            )\n        )\n        # Make a copy of relevant data, because Selenium will throw if\n        # you try to access the properties after the driver quit\n        elem = {\n          \"text\": found.text\n        }\n    finally:\n        driver.close()\n\n    return elem\n\ndef transform(elem):\n    return elem[\"text\"]\n        \ndef load(text, filepath):\n    cloud = WordCloud().generate(text)\n    cloud.to_file(filepath)\n\nif __name__ == \"__main__\":\n    url = \"https://angular.io/\"\n    filepath = \"angular.png\"\n\n    elem = extract(url)\n    if elem is not None:\n        text = transform(elem)\n        load(text, filepath)\n    else:\n        print(\"Sorry, could not extract data\")</code></pre><figcaption>crawler.py</figcaption></figure><p>Here, Python is opening a Firefox instance, browsing the website and looking for an <code>&lt;article&gt;</code> element. It is copying over its text into a dictionary, which gets read out in the <code>transform</code> step and turned into a WordCloud during <code>load</code>. </p><p>When dealing with JavaScript-heavy sites, it is often useful to use <a href=\"https://selenium-python.readthedocs.io/waits.html\">Waits</a> and perhaps run even <code><a href=\"https://selenium-python.readthedocs.io/api.html#selenium.webdriver.remote.webdriver.WebDriver.execute_script\">execute_script</a></code>to defer to JavaScript if needed.</p><h2 id=\"summary\">Summary</h2><p>Thanks for reading this far! Let's summarise what we've learned now:</p><ol><li>How to scrape a website with Python's <code>requests</code> package.</li><li>How to translate it into a meaningful structure using <code>beautifulsoup</code>.</li><li>How to further process that structure into something you can work with.</li><li>What to do if the target page is relying on JavaScript.</li></ol><h2 id=\"further-reading\">Further reading</h2><p>If you want to find more about me, you can <a href=\"https://twitter.com/AndreJaenisch\">follow me on Twitter</a> or visit <a href=\"https://jaenis.ch/\">my website</a>.</p><p>I'm not the first one who wrote about Web Scraping here on freeCodeCamp. Yasoob Khalid and Dave Gray also did so in the past:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.freecodecamp.org/news/an-intro-to-web-scraping-with-lxml-and-python-b02b7a3f3098/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">An Intro to Web Scraping with lxml and Python</div><div class=\"kg-bookmark-description\">by Timber.io An Intro to Web Scraping with lxml and PythonPhoto by Fabian Grohs[https://unsplash.com/photos/dC6Pb2JdAqs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText] on Unsplash[https://unsplash.com/search/photos/web?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText‚Ä¶</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.freecodecamp.org/news/favicon.png\" width=\"600\" height=\"400\" alt=\"favicon\" loading=\"lazy\"><span class=\"kg-bookmark-author\">freeCodeCamp.org</span><span class=\"kg-bookmark-publisher\">freeCodeCamp.org</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-media-1.freecodecamp.org/images/0*AXQfWm6LMJwLwS2f.png\" width=\"800\" height=\"357\" alt=\"0*AXQfWm6LMJwLwS2f\" loading=\"lazy\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.freecodecamp.org/news/better-web-scraping-in-python-with-selenium-beautiful-soup-and-pandas-d6390592e251/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Better web scraping in Python with Selenium, Beautiful Soup, and pandas</div><div class=\"kg-bookmark-description\">by Dave Gray Web ScrapingUsing the Python programming language, it is possible to ‚Äúscrape‚Äù data from theweb in a quick and efficient manner. Web scraping is defined as: &amp;gt; a tool for turning the unstructured data on the web into machine readable,structured data which is ready for analysis. (sou‚Ä¶</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.freecodecamp.org/news/favicon.png\" width=\"600\" height=\"400\" alt=\"favicon\" loading=\"lazy\"><span class=\"kg-bookmark-author\">freeCodeCamp.org</span><span class=\"kg-bookmark-publisher\">freeCodeCamp.org</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn-media-1.freecodecamp.org/images/1*DiffPQdgEAjDK4M_unUd4Q.jpeg\" width=\"800\" height=\"533\" alt=\"1*DiffPQdgEAjDK4M_unUd4Q\" loading=\"lazy\"></div></a></figure>\n\n                        </section>\n                        \n                            <div class=\"sidebar\">\n                                \n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                        <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                                    \n                                \n                            </div>\n                        \n                    </div>\n                    <hr>\n                    \n                        <div class=\"post-full-author-header\" data-test-label=\"author-header-with-bio\">\n                            \n                                \n    \n    \n    \n\n    <section class=\"author-card\" data-test-label=\"author-card\">\n        \n            \n    <img srcset=\"https://www.freecodecamp.org/news/content/images/size/w60/2021/05/andre-jaenisch-gravatar.jpeg 60w\" sizes=\"60px\" src=\"https://www.freecodecamp.org/news/content/images/size/w60/2021/05/andre-jaenisch-gravatar.jpeg\" class=\"author-profile-image\" alt=\"Andr√© Jaenisch\" width=\"250\" height=\"250\" onerror=\"this.style.display='none'\" loading=\"lazy\" data-test-label=\"profile-image\">\n  \n        \n\n        <section class=\"author-card-content \">\n            <span class=\"author-card-name\">\n                <a href=\"/news/author/ryuno-ki/\" data-test-label=\"profile-link\">\n                    \n                        Andr√© Jaenisch\n                    \n                </a>\n            </span>\n            \n                \n                    <p data-test-label=\"author-bio\">Studied mathematics with business science.\nSelf-taught Webdeveloper (JavaScript and Python).\nWorking as Frontend Engineer with Full Stack ambitions.</p>\n                \n            \n        </section>\n    </section>\n\n                            \n                        </div>\n                        <hr>\n                    \n\n                    \n                    \n                        \n    \n\n\n<p data-test-label=\"social-row-cta\" class=\"social-row\">\n    If you read this far, thank the author to show them you care. <button id=\"tweet-btn\" class=\"cta-button\" data-test-label=\"tweet-button\">Say Thanks</button>\n</p>\n\n\n    \n    <script>document.addEventListener(\"DOMContentLoaded\",(()=>{const t=document.getElementById(\"tweet-btn\"),e=window.location,n=\"How%20to%20Scrape%20Websites%20with%20Python%203\".replace(/&#39;/g,\"%27\"),o=\"\",i=\"@AndreJaenisch\",r=Boolean(\"\");let s;if(r&&(o||i)){const t={originalPostAuthor:\"\",currentPostAuthor:\"Andr√© Jaenisch\"};s=encodeURIComponent(`Thank you ${o||t.originalPostAuthor} for writing this helpful article, and ${i||t.currentPostAuthor} for translating it.`)}else!r&&i&&(s=encodeURIComponent(`Thank you ${i} for writing this helpful article.`));const c=`window.open(\\n    '${s?`https://twitter.com/intent/tweet?text=${s}%0A%0A${n}%0A%0A${e}`:`https://twitter.com/intent/tweet?text=${n}%0A%0A${e}`}',\\n    'share-twitter',\\n    'width=550, height=235'\\n  ); return false;`;t.setAttribute(\"onclick\",c)}));</script>\n\n\n                        \n\n<div class=\"learn-cta-row\" data-test-label=\"learn-cta-row\">\n    <p>\n        Learn to code for free. freeCodeCamp's open source curriculum has helped more than 40,000 people get jobs as developers. <a href=\"https://www.freecodecamp.org/learn/\" class=\"cta-button\" id=\"learn-to-code-cta\" rel=\"noopener noreferrer\" target=\"_blank\">Get started</a>\n    </p>\n</div>\n\n                    \n                </section>\n                \n                    <div class=\"banner-ad bottom\">\n                        \n                            <div class=\"ad-wrapper\" data-test-label=\"ad-wrapper\">\n    \n    <div class=\"ad-text\" data-test-label=\"ad-text\">ADVERTISEMENT</div>\n    <ins class=\"adsbygoogle\" style=\"display: block; height: 280px;\" data-ad-client=\"ca-pub-9482786369113753\" data-ad-slot=\"5720086888\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n</div>\n\n                        \n                    </div>\n                \n            </article>\n        </div>\n    </main>\n\n\n            \n\n\n<footer class=\"site-footer\">\n    <div class=\"footer-top\">\n        <div class=\"footer-desc-col\">\n            <p data-test-label=\"tax-exempt-status\">freeCodeCamp is a donor-supported tax-exempt 501(c)(3) charity organization (United States Federal Tax Identification Number: 82-0779546)</p>\n            <p data-test-label=\"mission-statement\">Our mission: to help people learn to code for free. We accomplish this by creating thousands of videos, articles, and interactive coding lessons - all freely available to the public.</p>\n            <p data-test-label=\"donation-initiatives\">Donations to freeCodeCamp go toward our education initiatives, and help pay for servers, services, and staff.</p>\n            <p class=\"footer-donation\" data-test-label=\"donate-text\">\n                You can <a href=\"https://www.freecodecamp.org/donate/\" class=\"inline\" rel=\"noopener noreferrer\" target=\"_blank\">make a tax-deductible donation here</a>.\n            </p>\n        </div>\n        <div class=\"trending-guides\" data-test-label=\"trending-guides\">\n            <h2 id=\"trending-guides\" class=\"col-header\">Trending Guides</h2>\n            <ul class=\"trending-guides-articles\" aria-labelledby=\"trending-guides\">\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/complete-guide-to-css-transform-functions-and-properties/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn CSS Transform\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/how-to-create-a-static-blog-with-lume/\" rel=\"noopener noreferrer\" target=\"_blank\">Build a Static Blog\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/how-to-build-an-ai-chatbot-with-redis-python-and-gpt/\" rel=\"noopener noreferrer\" target=\"_blank\">Build an AI Chatbot\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/what-is-programming-tutorial-for-beginners/\" rel=\"noopener noreferrer\" target=\"_blank\">What is Programming?\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/python-code-examples-sample-script-coding-tutorial-for-beginners/\" rel=\"noopener noreferrer\" target=\"_blank\">Python Code Examples\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/a-practical-guide-to-start-opensource-contributions/\" rel=\"noopener noreferrer\" target=\"_blank\">Open Source for Devs\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/http-full-course/\" rel=\"noopener noreferrer\" target=\"_blank\">HTTP Networking in JS\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/how-to-write-unit-tests-in-react-redux/\" rel=\"noopener noreferrer\" target=\"_blank\">Write React Unit Tests\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/introduction-to-algorithms-with-javascript-examples/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Algorithms in JS\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/how-to-write-clean-code/\" rel=\"noopener noreferrer\" target=\"_blank\">How to Write Clean Code\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/the-php-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn PHP\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/the-java-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Java\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/the-swift-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Swift\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/learn-golang-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Golang\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/get-started-with-nodejs/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Node.js\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/complete-guide-to-css-grid/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn CSS Grid\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/learn-solidity-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Solidity\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/the-express-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Express.js\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/javascript-es-modules-and-module-bundlers/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn JS Modules\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/apache-kafka-handbook/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn Apache Kafka\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/rest-api-design-best-practices-build-a-rest-api/\" rel=\"noopener noreferrer\" target=\"_blank\">REST API Best Practices\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/front-end-javascript-development-react-angular-vue-compared/\" rel=\"noopener noreferrer\" target=\"_blank\">Front-End JS Development\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/build-consume-and-document-a-rest-api/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn to Build REST APIs\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/build-strongly-typed-polymorphic-components-with-react-and-typescript/\" rel=\"noopener noreferrer\" target=\"_blank\">Intermediate TS and React\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/command-line-for-beginners/\" rel=\"noopener noreferrer\" target=\"_blank\">Command Line for Beginners\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/an-introduction-to-operating-systems/\" rel=\"noopener noreferrer\" target=\"_blank\">Intro to Operating Systems\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/building-consuming-and-documenting-a-graphql-api/\" rel=\"noopener noreferrer\" target=\"_blank\">Learn to Build GraphQL APIs\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/oss-security-best-practices/\" rel=\"noopener noreferrer\" target=\"_blank\">OSS Security Best Practices\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/design-patterns-for-distributed-systems/\" rel=\"noopener noreferrer\" target=\"_blank\">Distributed Systems Patterns\n                    </a>\n                </li>\n                <li>\n                    <a href=\"https://www.freecodecamp.org/news/an-introduction-to-software-architecture-patterns/\" rel=\"noopener noreferrer\" target=\"_blank\">Software Architecture Patterns\n                    </a>\n                </li>\n            </ul>\n            <div class=\"spacer\" style=\"padding: 15px 0;\"></div>\n            <div>\n                <h2 id=\"mobile-app\" class=\"col-header\">\n                    Mobile App\n                </h2>\n                <div class=\"min-h-[1px] px-[15px] md:w-2/3 md:ml-[16.6%]\">\n                    <ul aria-labelledby=\"mobile-app\" class=\"mobile-app-container\">\n                        <li>\n                            <a href=\"https://apps.apple.com/us/app/freecodecamp/id6446908151?itsct=apps_box_link&itscg=30200\" rel=\"noopener noreferrer\" target=\"_blank\">\n                                <img src=\"https://cdn.freecodecamp.org/platform/universal/apple-store-badge.svg\" lang=\"en\" alt=\"Download on the App Store\">\n                            </a>\n                        </li>\n                        <li>\n                            <a href=\"https://play.google.com/store/apps/details?id=org.freecodecamp\" rel=\"noopener noreferrer\" target=\"_blank\">\n                                <img src=\"https://cdn.freecodecamp.org/platform/universal/google-play-badge.svg\" lang=\"en\" alt=\"Get it on Google Play\">\n                            </a>\n                        </li>\n                    </ul>\n                </div>\n            </div>\n        </div>\n    </div>\n    <div class=\"footer-bottom\">\n        <h2 class=\"col-header\" data-test-label=\"our-nonprofit\">Our Charity</h2>\n        <div class=\"our-nonprofit\">\n            <a href=\"https://www.freecodecamp.org/news/about/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"about\">\n                About\n            </a>\n            <a href=\"https://www.linkedin.com/school/free-code-camp/people/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"alumni\">\n                Alumni Network\n            </a>\n            <a href=\"https://github.com/freeCodeCamp/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"open-source\">\n                Open Source\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/shop/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"shop\">\n                Shop\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/support/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"support\">\n                Support\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/sponsors/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"sponsors\">\n                Sponsors\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/academic-honesty-policy/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"honesty\">\n                Academic Honesty\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/code-of-conduct/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"coc\">\n                Code of Conduct\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/privacy-policy/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"privacy\">\n                Privacy Policy\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/terms-of-service/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"tos\">\n                Terms of Service\n            </a>\n            <a href=\"https://www.freecodecamp.org/news/copyright-policy/\" rel=\"noopener noreferrer\" target=\"_blank\" data-test-label=\"copyright\">\n                Copyright Policy\n            </a>\n        </div>\n    </div>\n</footer>\n\n        </div>\n\n        \n        \n        \n\n        <!-- Google Tag Manager (noscript) -->\n<noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-5D6RKKP\" height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\n<!-- End Google Tag Manager (noscript) -->\n\n        \n    <script defer src=\"https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015\" integrity=\"sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==\" data-cf-beacon='{\"rayId\":\"8ac085a32dc56032\",\"version\":\"2024.7.0\",\"serverTiming\":{\"name\":{\"cfL4\":true}},\"token\":\"bdb993c6dde44e178aabd9555e75e4f4\",\"b\":1}' crossorigin=\"anonymous\"></script>\n</body>\n</html>\n"}}}